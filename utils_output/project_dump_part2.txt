================================================================================
FIL: archive/scripts/filter_gothenburg.py
================================================================================

#!/usr/bin/env python3
"""
scripts/filter_gothenburg.py
-----------------------------
Extract all G√∂teborg-municipality companies from a raw SCB bulk file
(and build a full street address for each) by filtering on the
canonical 20 district names.

Usage:
    python scripts/filter_gothenburg.py \
      --input /home/bakri/Desktop/scb_bulkfil/scb_bulkfil_JE_20250512T094258_21.txt
"""

import argparse
import sys
from pathlib import Path

import pandas as pd

# Logical field names we need
DESIRED = ["PeOrgNr", "Gatuadress", "PostNr", "PostOrt"]

# The 20 official G√∂teborg municipality districts
DISTRICTS = [
    "Agnesberg", "Angered", "Askim", "Asper√∂", "Billdal",
    "Br√§nn√∂", "Dons√∂", "Gunnilse", "G√∂teborg", "Hisings Backa",
    "Hisings K√§rra", "Hov√•s", "Kung√§lv", "K√∂pstads√∂", "Olofstorp",
    "Styrs√∂", "S√§ve", "Torslanda", "Vr√•ng√∂", "V√§stra Fr√∂lunda",
]
# Lower-case set for filtering, and map back for canonical casing
LOWER_DISTRICTS = {d.lower() for d in DISTRICTS}
DISTRICT_MAP = {d.lower(): d for d in DISTRICTS}


def infer_columns(header_cols: list[str]) -> dict[str, str]:
    """
    From the raw header_cols, find which actual column corresponds
    to each name in DESIRED. Returns mapping actual_name -> desired_name.
    Exits if any desired field is missing.
    """
    # map stripped, lower-cased to the real header
    lookup = {col.strip().lower(): col for col in header_cols}
    mapping: dict[str, str] = {}
    for want in DESIRED:
        key = want.lower()
        if key not in lookup:
            print(f"üõë Missing required column '{want}' in SCB header.", file=sys.stderr)
            print("Available columns:", file=sys.stderr)
            for col in header_cols:
                print("   ", repr(col), file=sys.stderr)
            sys.exit(1)
        actual = lookup[key]
        mapping[actual] = want
    return mapping


def main(scb_path: Path):
    print(f"Reading SCB header from {scb_path} ‚Ä¶")
    # 1) Sniff header to get actual column names (tab-separated, Latin-1)
    header_df = pd.read_csv(
        scb_path,
        sep="\t",
        nrows=0,
        encoding="latin1",
        low_memory=False
    )
    actual_cols = list(header_df.columns)

    # 2) Infer which actual names match our DESIRED fields
    col_map = infer_columns(actual_cols)

    # 3) Load only those columns
    print("Loading columns:", list(col_map.keys()))
    df = pd.read_csv(
        scb_path,
        sep="\t",
        usecols=list(col_map.keys()),
        dtype=str,
        encoding="latin1",
        low_memory=False
    )

    # 4) Rename to our standard logical names
    df = df.rename(columns=col_map)

    # 5) Filter to entries whose PostOrt is one of the 20 districts
    df["PostOrt_norm"] = df["PostOrt"].str.strip().str.lower()
    df = df[df["PostOrt_norm"].isin(LOWER_DISTRICTS)].copy()
    print(f"‚Üí {len(df)} firms in G√∂teborg municipality")

    # 6) Normalize the district back to canonical casing
    df["district"] = df["PostOrt_norm"].map(DISTRICT_MAP)

    # 7) Build a full street address
    df["registered_address"] = (
        df["Gatuadress"].str.strip()
        + ", "
        + df["PostNr"].str.strip()
        + " "
        + df["district"]
    )

    # 8) Output the key fields
    out = df[["PeOrgNr", "district", "registered_address"]]

    dest = Path("data") / "gothenburg_companies_addresses.csv"
    dest.parent.mkdir(parents=True, exist_ok=True)
    out.to_csv(dest, index=False, encoding="utf-8")
    print(f"Wrote {len(out)} rows to {dest}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Filter SCB dump to G√∂teborg municipality and build full addresses"
    )
    parser.add_argument(
        "--input", "-i",
        type=Path,
        required=True,
        help="Path to your raw SCB dump file (tab-separated, Latin-1 .txt)"
    )
    args = parser.parse_args()
    main(args.input)


================================================================================
FIL: archive/scripts/geocode_gothenburg_companies.py
================================================================================

#!/usr/bin/env python3
"""
scripts/geocode_gothenburg_companies.py
---------------------------------------
Geocode Gothenburg company addresses with:
 - normalization (cache-friendly),
 - disk-cached results,
 - periodic checkpointing,
 - custom Nominatim endpoint support,
 - thread-based parallelism + RateLimiter (1 req/sec).
"""

import logging
import os
import pickle
import re
import time
from argparse import ArgumentParser
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
from typing import Dict, Tuple, Optional

import pandas as pd
from geopy.extra.rate_limiter import RateLimiter
from geopy.geocoders import Nominatim
from tqdm import tqdm

# -----------------------------------------------------------------------------
# CONFIG
# -----------------------------------------------------------------------------
CACHE_FILE = Path("data/geocode_cache.pkl")
CHECKPOINT_INTERVAL = 1000    # save cache & partial CSV every N addresses
NOMINATIM_URL = os.getenv("NOMINATIM_URL", "https://nominatim.openstreetmap.org")
USER_AGENT   = "sponsor_match_geo"
# -----------------------------------------------------------------------------

logging.basicConfig(
    format="%(asctime)s %(levelname)s %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

def normalize_address(addr: str) -> str:
    """Lowercase, strip punctuation, standardize spacing & common terms."""
    s = addr.strip().lower()
    s = re.sub(r"[,.]", "", s)               # remove commas, periods
    s = re.sub(r"\bgatan\b", "g", s)         # 'gatan' ‚Üí 'g'
    s = re.sub(r"\s+", " ", s)               # collapse whitespace
    return s

def load_cache() -> Dict[str, Tuple[Optional[float], Optional[float]]]:
    if CACHE_FILE.exists():
        with open(CACHE_FILE, "rb") as f:
            cache = pickle.load(f)
        logger.info("Loaded %d cached addresses", len(cache))
    else:
        cache = {}
        logger.info("No existing cache; starting fresh")
    return cache

def save_cache(cache: Dict[str, Tuple[Optional[float], Optional[float]]]):
    CACHE_FILE.parent.mkdir(exist_ok=True, parents=True)
    with open(CACHE_FILE, "wb") as f:
        pickle.dump(cache, f)  # type: ignore
    logger.info("Checkpoint: saved cache (%d entries)", len(cache))

def geocode_worker_init():
    """Initialize one shared geocoder + rate limiter per thread."""
    geocoder = Nominatim(
        user_agent=USER_AGENT,
        timeout=10,
        domain=NOMINATIM_URL.replace("https://", "").replace("http://", ""),
        scheme=NOMINATIM_URL.split("://")[0]
    )
    limiter = RateLimiter(geocoder.geocode, min_delay_seconds=1.1)
    globals()["_limiter"] = limiter

def geocode_one(addr_norm: str) -> Tuple[str, Optional[float], Optional[float]]:
    """Try geocoding two variants; return (normalized_address, lat, lon)."""
    for query in (addr_norm, f"{addr_norm}, sweden"):
        try:
            loc = globals()["_limiter"](query, country_codes="se", exactly_one=True)
        except ExceptionGroup as eg:
            # Python 3.11+: multiple errors in one go
            for sub in eg.exceptions:
                logger.debug("Sub-error for %r: %s", query, sub)
            time.sleep(2)
            continue
        except Exception as e:
            # any other single error (timeout, network, etc.)
            logger.debug("Error for %r: %s", query, e)
            time.sleep(2)
            continue

        if loc:
            return addr_norm, loc.latitude, loc.longitude

    return addr_norm, None, None

def parse_args():
    p = ArgumentParser(description="Geocode Gothenburg addresses w/ caching & threads")
    p.add_argument("--log-level", "-L", choices=["DEBUG","INFO","WARN","ERROR"], default="INFO")
    p.add_argument("-w", "--workers", type=int, default=4, help="Thread count")
    p.add_argument("--no-progress", action="store_true", help="Hide tqdm bar")
    p.add_argument("in_csv",  type=Path, help="Input CSV with 'address' or 'registered_address'")
    p.add_argument("out_csv", type=Path, help="Output CSV with lat,lon appended")
    return p.parse_args()

def main():
    args = parse_args()
    logging.getLogger().setLevel(getattr(logging, args.log_level))

    # 1) Load data
    df = pd.read_csv(args.in_csv, dtype=str)
    if "address" not in df.columns:
        if "registered_address" in df.columns:
            df["address"] = df["registered_address"]
        else:
            logger.error("Need column 'address' or 'registered_address'")
            return

    # 2) Normalize
    df["address_norm"] = df["address"].map(normalize_address)

    # 3) Load cache & build list
    cache = load_cache()
    unique_norm = df["address_norm"].dropna().unique().tolist()
    to_geo = [a for a in unique_norm if a not in cache]
    logger.info("Need to geocode %d/%d unique addresses", len(to_geo), len(unique_norm))

    # 4) Parallel geocode with checkpointing
    if to_geo:
        with ThreadPoolExecutor(max_workers=args.workers,
                                initializer=geocode_worker_init) as exe:
            futures = {exe.submit(geocode_one, addr): addr for addr in to_geo}
            it = tqdm(as_completed(futures), total=len(futures),
                      desc="Geocoding", disable=args.no_progress)
            for i, fut in enumerate(it, start=1):
                addr = futures[fut]
                try:
                    _, lat, lon = fut.result()
                except ExceptionGroup as eg:
                    # should never hit here‚Äîhandled in geocode_one‚Äîbut just in case:
                    for sub in eg.exceptions:
                        logger.debug("Late sub-error for %r: %s", addr, sub)
                    lat, lon = None, None
                except Exception as e:
                    logger.debug("Late error for %r: %s", addr, e)
                    lat, lon = None, None

                cache[addr] = (lat, lon)

                # checkpoint every N
                if i % CHECKPOINT_INTERVAL == 0:
                    save_cache(cache)
                    # write partial CSV
                    outp = args.out_csv.with_suffix(".partial.csv")
                    df_partial = df[df["address_norm"].isin(cache)]
                    df_partial["lat"] = df_partial["address_norm"].map(lambda x: cache[x][0])
                    df_partial["lon"] = df_partial["address_norm"].map(lambda x: cache[x][1])
                    df_partial.to_csv(outp, index=False)
                    logger.info("Partial CSV (%d rows) ‚Üí %s", len(df_partial), outp)

        save_cache(cache)

    # 5) Map coords back to full DF
    df["lat"] = df["address_norm"].map(lambda x: cache.get(x, (None, None))[0])
    df["lon"] = df["address_norm"].map(lambda x: cache.get(x, (None, None))[1])

    # 6) Write final
    args.out_csv.parent.mkdir(exist_ok=True, parents=True)
    df.to_csv(args.out_csv, index=False)
    logger.info("Wrote %d rows to %s", len(df), args.out_csv)

if __name__ == "__main__":
    main()


================================================================================
FIL: archive/scripts/ingest_associations.py
================================================================================

#!/usr/bin/env python3
"""
sponsor_match/data/ingest_associations.py

Reads an enriched associations CSV and ingests it into the MySQL database.
"""

import argparse
import logging
from pathlib import Path

import pandas as pd
from sqlalchemy.exc import SQLAlchemyError
from sponsor_match.core.db import get_engine
from dotenv import load_dotenv

def init_logging():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s %(levelname)s %(message)s"
    )

def ingest(csv_path: Path):
    """
    Load the CSV at csv_path into the `associations` table.
    Replaces any existing data in `associations`.
    """
    if not csv_path.exists():
        logging.error(f"CSV file not found: {csv_path}")
        return

    try:
        df = pd.read_csv(csv_path)
        logging.info(f"Loaded {len(df)} rows from {csv_path}")
    except Exception as e:
        logging.error(f"Failed to read CSV {csv_path}: {e}")
        return

    engine = get_engine()
    try:
        with engine.begin() as conn:
            df.to_sql(
                name="associations",
                con=conn,
                if_exists="replace",
                index=False,
                method="multi",      # batch inserts if available
            )
        logging.info(f"Successfully wrote {len(df)} rows to `associations` table.")
    except SQLAlchemyError as e:
        logging.error(f"Database error during ingest: {e}")
    except Exception as e:
        logging.error(f"Unexpected error during ingest: {e}")

def main():
    load_dotenv()    # ensure .env credentials are loaded
    init_logging()

    parser = argparse.ArgumentParser(
        description="Ingest enriched associations CSV into MySQL `associations` table"
    )
    parser.add_argument(
        "--csv-path",
        type=Path,
        default=Path("data") / "associations_goteborg_with_coords.csv",
        help="Path to the enriched associations CSV file",
    )
    args = parser.parse_args()
    ingest(args.csv_path)

if __name__ == "__main__":
    main()


================================================================================
FIL: archive/debug/__init__.py
================================================================================



================================================================================
FIL: archive/debug/debug_report_20250514_182948.json
================================================================================

{
  "timestamp": "2025-05-14T18:29:48.158760",
  "steps": [
    {
      "name": "Database Connection",
      "timestamp": "2025-05-14T18:29:47.290579",
      "success": false,
      "error": "type object 'Config' has no attribute 'MYSQL_URL'"
    },
    {
      "name": "Entity Loading",
      "timestamp": "2025-05-14T18:29:47.472970",
      "success": false,
      "error": "Column expression, FROM clause, or other columns clause element expected, got <class 'sponsor_match.models.entities.Club'>."
    },
    {
      "name": "Service Layer",
      "timestamp": "2025-05-14T18:29:47.531033",
      "success": false,
      "error": "SponsorMatchService.__init__() missing 2 required positional arguments: 'db_engine' and 'cluster_models'"
    },
    {
      "name": "Distance Calculation",
      "timestamp": "2025-05-14T18:29:47.531844",
      "success": true,
      "error": null
    },
    {
      "name": "Search Functionality",
      "timestamp": "2025-05-14T18:29:47.532722",
      "success": false,
      "error": "Column expression, FROM clause, or other columns clause element expected, got <class 'sponsor_match.models.entities.Club'>."
    },
    {
      "name": "UI Integration",
      "timestamp": "2025-05-14T18:29:48.158534",
      "success": true,
      "error": null
    }
  ],
  "errors": [
    [
      "Database Connection",
      "type object 'Config' has no attribute 'MYSQL_URL'"
    ],
    [
      "Entity Loading",
      "Column expression, FROM clause, or other columns clause element expected, got <class 'sponsor_match.models.entities.Club'>."
    ],
    [
      "Service Layer",
      "SponsorMatchService.__init__() missing 2 required positional arguments: 'db_engine' and 'cluster_models'"
    ],
    [
      "Search Functionality",
      "Column expression, FROM clause, or other columns clause element expected, got <class 'sponsor_match.models.entities.Club'>."
    ]
  ],
  "data_snapshots": {
    "Distance Calculation": {
      "distance": 1.2774467019526492
    },
    "UI Integration": {
      "methods": [
        "clubs_df",
        "engine",
        "render_main_page"
      ],
      "search_methods": []
    }
  }
}

================================================================================
FIL: archive/debug/discover_structure.py
================================================================================

# debug/discover_structure.py
"""
Module Structure Discovery Tool

This script helps identify the actual structure of your SponsorMatchAI project
so we can fix import errors in the test scripts.
"""

import os
import sys
from pathlib import Path
import ast
import json

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def find_python_files(directory):
    """Find all Python files in the directory"""
    python_files = []
    for root, dirs, files in os.walk(directory):
        # Skip virtual environments and cache
        dirs[:] = [d for d in dirs if d not in {'venv', '.venv', '__pycache__', '.git'}]
        for file in files:
            if file.endswith('.py'):
                python_files.append(Path(root) / file)
    return python_files


def analyze_file(filepath):
    """Analyze a Python file to find classes and functions"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        tree = ast.parse(content)

        functions = []
        classes = []
        imports = []

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append(node.name)
            elif isinstance(node, ast.ClassDef):
                classes.append(node.name)
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(f"from {node.module}")

        return {
            'functions': functions,
            'classes': classes,
            'imports': imports
        }
    except Exception as e:
        return {'error': str(e)}


def main():
    print("SponsorMatchAI Structure Discovery")
    print("=" * 40)

    sponsor_match_dir = project_root / 'sponsor_match'

    if not sponsor_match_dir.exists():
        print(f"Error: sponsor_match directory not found at {sponsor_match_dir}")
        return

    print(f"Analyzing {sponsor_match_dir}...\n")

    # Find all Python files
    python_files = find_python_files(sponsor_match_dir)

    # Analyze structure
    structure = {}

    for file in python_files:
        relative_path = file.relative_to(project_root)
        analysis = analyze_file(file)

        if 'error' not in analysis:
            structure[str(relative_path)] = analysis
            print(f"\n{relative_path}")

            if analysis['classes']:
                print(f"  Classes: {', '.join(analysis['classes'][:5])}")

            if analysis['functions']:
                print(f"  Functions: {', '.join(analysis['functions'][:5])}")
                if len(analysis['functions']) > 5:
                    print(f"    ... and {len(analysis['functions']) - 5} more")

    # Look for specific modules we need
    print("\n\nSearching for key components:")
    print("-" * 30)

    key_patterns = {
        'database': ['db', 'database', 'connection'],
        'config': ['config', 'settings', 'Config'],
        'distance': ['distance', 'calculate_distance', 'haversine'],
        'matching': ['match', 'matcher', 'find_matches', 'search'],
        'streamlit': ['app', 'ui', 'streamlit'],
        'ingest': ['ingest', 'import', 'parse']
    }

    for component, patterns in key_patterns.items():
        print(f"\n{component.upper()}:")
        found = False
        for filepath, content in structure.items():
            for pattern in patterns:
                if pattern in filepath.lower():
                    print(f"  File: {filepath}")
                    found = True
                    break

                for func in content.get('functions', []):
                    if pattern in func.lower():
                        print(f"  Function '{func}' in {filepath}")
                        found = True

                for cls in content.get('classes', []):
                    if pattern in cls.lower():
                        print(f"  Class '{cls}' in {filepath}")
                        found = True

        if not found:
            print(f"  Not found - this component might not exist")

    # Save the structure for reference
    output_file = Path(__file__).parent / 'project_structure.json'

    with open(output_file, 'w') as f:
        json.dump(structure, f, indent=2)

    print(f"\n\nStructure saved to: {output_file}")
    print("\nNext steps:")
    print("1. Share the output with me")
    print("2. I'll create corrected versions of the test scripts")
    print("3. We'll fix the import errors properly")


if __name__ == "__main__":
    main()


================================================================================
FIL: archive/debug/project_structure.json
================================================================================

{
  "sponsor_match/features.py": {
    "functions": [
      "calculate_distance_km",
      "add_distance",
      "bucket_assoc_size",
      "make_pair_features",
      "_size_score"
    ],
    "classes": [],
    "imports": [
      "from typing",
      "numpy",
      "pandas",
      "from geopy.distance",
      "from pandas"
    ]
  },
  "sponsor_match/services/recommendation.py": {
    "functions": [
      "__init__",
      "recommend"
    ],
    "classes": [
      "RecommendationService"
    ],
    "imports": [
      "logging",
      "from typing",
      "from sponsor_match.core.db",
      "from sponsor_match.services.service_v2"
    ]
  },
  "sponsor_match/services/service_v2.py": {
    "functions": [
      "__init__",
      "_get_club_by_id",
      "_find_matching_companies",
      "_calculate_scores",
      "recommend"
    ],
    "classes": [
      "RecommendationRequest",
      "RecommendationResult",
      "SponsorMatchService"
    ],
    "imports": [
      "logging",
      "uuid",
      "from dataclasses",
      "from typing",
      "pandas",
      "numpy",
      "from geopy.distance"
    ]
  },
  "sponsor_match/cli/__init__.py": {
    "functions": [],
    "classes": [],
    "imports": []
  },
  "sponsor_match/cli/train_matcher.py": {
    "functions": [
      "main"
    ],
    "classes": [],
    "imports": [
      "logging",
      "from argparse",
      "from pathlib",
      "pandas",
      "joblib",
      "from sklearn.model_selection",
      "from sklearn.ensemble",
      "from sponsor_match.features"
    ]
  },
  "sponsor_match/cli/db_init.py": {
    "functions": [
      "main"
    ],
    "classes": [],
    "imports": [
      "logging",
      "from argparse",
      "from textwrap",
      "from sponsor_match.core.db"
    ]
  },
  "sponsor_match/ui/app_v2.py": {
    "functions": [
      "main",
      "__init__",
      "_load_clubs",
      "_marker_color",
      "_club_popup",
      "_company_popup",
      "_radar_chart",
      "_run_search",
      "_render_recommendations",
      "_render_analytics",
      "_render_map",
      "_render_insights",
      "render_main_page"
    ],
    "classes": [
      "SponsorMatchUI"
    ],
    "imports": [
      "logging",
      "from pathlib",
      "joblib",
      "pandas",
      "plotly.express",
      "plotly.graph_objects",
      "streamlit",
      "from folium",
      "from folium.map",
      "from folium.plugins",
      "from streamlit_folium",
      "from sponsor_match.core.config",
      "from sponsor_match.core.db",
      "from sponsor_match.services.service_v2"
    ]
  },
  "sponsor_match/ui/__init__.py": {
    "functions": [],
    "classes": [],
    "imports": []
  },
  "sponsor_match/core/config.py": {
    "functions": [],
    "classes": [
      "Config"
    ],
    "imports": [
      "os",
      "from dataclasses",
      "from pathlib",
      "from dotenv"
    ]
  },
  "sponsor_match/core/logger.py": {
    "functions": [
      "setup_logger"
    ],
    "classes": [],
    "imports": [
      "logging",
      "sys",
      "from pathlib"
    ]
  },
  "sponsor_match/core/db.py": {
    "functions": [
      "get_engine"
    ],
    "classes": [],
    "imports": [
      "os",
      "logging",
      "from pathlib",
      "from dotenv",
      "from sqlalchemy",
      "from sqlalchemy.engine",
      "from sponsor_match.core.config"
    ]
  },
  "sponsor_match/models/clustering.py": {
    "functions": [
      "train_kmeans_for_bucket",
      "main"
    ],
    "classes": [],
    "imports": [
      "logging",
      "from pathlib",
      "joblib",
      "pandas",
      "from sklearn.cluster",
      "from sponsor_match.core.db",
      "from sponsor_match.core.config"
    ]
  },
  "sponsor_match/models/club_extended.py": {
    "functions": [],
    "classes": [
      "ExtendedClub"
    ],
    "imports": [
      "from dataclasses",
      "from typing"
    ]
  },
  "sponsor_match/models/__init__.py": {
    "functions": [],
    "classes": [],
    "imports": []
  },
  "sponsor_match/models/models.py": {
    "functions": [
      "__init__",
      "train",
      "predict_proba"
    ],
    "classes": [
      "SponsorshipPredictorEnsemble"
    ],
    "imports": [
      "logging",
      "from typing",
      "numpy",
      "pandas",
      "from sklearn.ensemble",
      "from sklearn.neural_network",
      "lightgbm"
    ]
  },
  "sponsor_match/models/entities.py": {
    "functions": [],
    "classes": [
      "Club",
      "Company"
    ],
    "imports": [
      "from dataclasses",
      "from typing"
    ]
  },
  "sponsor_match/models/features.py": {
    "functions": [
      "calculate_distance",
      "calculate_size_match",
      "calculate_industry_affinity",
      "calculate_growth_rate",
      "urban_rural_compatibility",
      "create_features",
      "_dist",
      "_score",
      "_affinity"
    ],
    "classes": [
      "FeatureEngineer"
    ],
    "imports": [
      "numpy",
      "pandas",
      "from datetime",
      "from typing",
      "from geopy.distance"
    ]
  },
  "sponsor_match/data/__init__.py": {
    "functions": [],
    "classes": [],
    "imports": []
  },
  "sponsor_match/data/ingest_associations.py": {
    "functions": [
      "main"
    ],
    "classes": [],
    "imports": [
      "logging",
      "from argparse",
      "from pathlib",
      "pandas",
      "from sqlalchemy"
    ]
  },
  "sponsor_match/data/ingest_csv.py": {
    "functions": [
      "main"
    ],
    "classes": [],
    "imports": [
      "sys",
      "logging",
      "from pathlib",
      "pandas",
      "from sqlalchemy",
      "from sponsor_match.core.db"
    ]
  }
}

================================================================================
FIL: archive/debug/search_issue_debugger.py
================================================================================

import os
from typing import Dict, Any

import pandas as pd
import streamlit as st

# Fallback if st.modal isn't available
_open_modal = getattr(st, "modal", st.expander)


def load_csv_data():
    """Load association data from CSV instead of database connection"""
    # Path to the CSV file - adjust as needed
    csv_path = os.path.join("data", "associations_goteborg_with_coords.csv")

    try:
        # Attempt to load the CSV file
        associations_df = pd.read_csv(csv_path)
        return associations_df
    except Exception as e:
        # If the file can't be loaded, create a sample dataframe with test data
        st.warning(f"Could not load CSV file: {str(e)}")
        st.warning("Using sample data instead.")

        # Create sample data based on the structure you provided
        sample_data = {
            "id": [1, 2, 3, 4, 5],
            "name": ["IFK G√∂teborg", "GAIS", "BK H√§cken", "√ñrgryte IS", "G√∂teborgs Roddklubb"],
            "member_count": [1500, 800, 950, 600, 150],
            "address": [
                "Kamratgatan 1, 41528 G√∂teborg",
                "Gamla Ullevi, 41128 G√∂teborg",
                "Rambergsvallen, 41752 G√∂teborg",
                "K√§rralundsvallen, 41670 G√∂teborg",
                "F√§rjen√§sparken, 41804 G√∂teborg"
            ],
            "lat": [57.7084, 57.7102, 57.7193, 57.7041, 57.6941],
            "lon": [11.9746, 11.9866, 11.9367, 12.0027, 11.9124],
            "size_bucket": ["large", "medium", "medium", "medium", "small"]
        }
        return pd.DataFrame(sample_data)


class SponsorMatchUI:
    def __init__(self) -> None:
        st.set_page_config(
            page_title="Golden Sugar Daddy Goal",
            page_icon="‚öΩ",
            layout="wide",
            initial_sidebar_state="collapsed",
        )

    def render_main_page(self) -> None:
        # Enhanced CSS for better visual appearance
        st.markdown(
            """
            <style>
                /* Core Layout Structure */
                [data-testid="stAppViewContainer"] {
                    background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
                }

                /* Main content area */
                .main-content {
                    background: white;
                    border-radius: 12px;
                    padding: 2rem;
                    max-width: 1200px;
                    margin: 1rem auto;
                    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.08);
                }

                /* Headings with enhanced styling */
                h1 {
                    color: #1e3a8a !important;
                    font-weight: 800 !important;
                    font-size: 2.5rem !important;
                    text-align: center;
                    margin-bottom: 1.5rem !important;
                    text-shadow: 0 1px 2px rgba(0,0,0,0.1);
                }

                h2 {
                    color: #1e3a8a !important;
                    font-weight: 700 !important;
                    font-size: 1.8rem !important;
                    margin-bottom: 1.2rem !important;
                    border-bottom: 2px solid #e0f2fe;
                    padding-bottom: 0.5rem;
                }

                h3 {
                    color: #1e40af !important;
                    font-weight: 600 !important;
                    font-size: 1.4rem !important;
                    margin-bottom: 1rem !important;
                    margin-top: 1.5rem !important;
                }

                /* Paragraph text */
                p, label, div:not(.main-content) {
                    color: #334155 !important;
                    line-height: 1.6 !important;
                }

                /* Enhanced tabs styling */
                .stTabs [data-baseweb="tab-list"] {
                    gap: 4px;
                    background-color: #1e3a8a !important;
                    border-radius: 10px;
                    padding: 6px 8px;
                    max-width: 800px;
                    margin: 0 auto 1.5rem auto;
                }

                .stTabs [data-baseweb="tab"] {
                    height: auto;
                    padding: 8px 24px;
                    color: white !important;
                    border-radius: 8px;
                    font-weight: 500;
                    margin: 0 2px;
                }

                .stTabs [aria-selected="true"] {
                    background-color: #2563eb !important;
                    border-radius: 8px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.2);
                }

                /* Form elements with better styling */
                [data-testid="stTextInput"] > div > div > input,
                [data-testid="stNumberInput"] > div > div > input,
                [data-testid="stTextArea"] > div > div > textarea {
                    background-color: white;
                    color: #1e293b;
                    border: 1px solid #cbd5e1;
                    border-radius: 8px;
                    padding: 12px 16px;
                    box-shadow: 0 1px 3px rgba(0,0,0,0.05);
                    font-size: 16px;
                }

                /* Button styling */
                .stButton > button {
                    background-color: #1e40af !important;
                    color: white !important;
                    font-weight: 500 !important;
                    padding: 0.625rem 1.5rem !important;
                    border-radius: 8px !important;
                    border: none !important;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;
                    transition: all 0.2s !important;
                }

                .stButton > button:hover {
                    background-color: #1e3a8a !important;
                    transform: translateY(-1px);
                    box-shadow: 0 4px 8px rgba(0,0,0,0.15) !important;
                }

                /* Map container */
                .folium-map {
                    width: 100% !important;
                    min-height: 500px !important;
                    border-radius: 10px !important;
                    border: 1px solid #e2e8f0 !important;
                    box-shadow: 0 4px 8px rgba(0,0,0,0.08) !important;
                }

                /* Card styling */
                .content-card {
                    background: white;
                    border-radius: 10px;
                    padding: 1.5rem;
                    margin-bottom: 1.5rem;
                    border: 1px solid #e2e8f0;
                    box-shadow: 0 2px 6px rgba(0,0,0,0.05);
                }

                /* Company card styling */
                .company-card {
                    background: white;
                    border: 1px solid #e5e7eb;
                    border-radius: 8px;
                    padding: 1rem;
                    margin-bottom: 0.75rem;
                    transition: all 0.2s;
                }

                .company-card:hover {
                    border-color: #2563eb;
                    box-shadow: 0 2px 8px rgba(37, 99, 235, 0.15);
                    transform: translateY(-1px);
                }

                .company-card.selected {
                    background-color: #e6f2ff;
                    border: 2px solid #2563eb;
                }

                /* Sidebar styling */
                [data-testid="stSidebar"] {
                    background-color: #1e3a8a !important;
                    background-image: linear-gradient(180deg, #1e3a8a 0%, #2563eb 100%);
                    padding-top: 2rem !important;
                }

                [data-testid="stSidebar"] h1, 
                [data-testid="stSidebar"] h2, 
                [data-testid="stSidebar"] h3 {
                    color: white !important;
                }

                [data-testid="stSidebar"] button {
                    background-color: white !important;
                    color: #1e3a8a !important;
                }

                /* Hide default hamburger & footer */
                #MainMenu, footer { visibility: hidden; }
            </style>
            """,
            unsafe_allow_html=True
        )

        # Center the title
        st.markdown("<h1>Golden Sugar Daddy Goal</h1>", unsafe_allow_html=True)

        # Use Streamlit's native tabs
        tab1, tab2, tab3, tab4 = st.tabs(["üè† Hem", "üéØ Hitta sponsorer", "‚öôÔ∏è Inst√§llningar", "üë§ Min f√∂rening"])

        # Main content wrapper for each tab
        with tab1:
            st.markdown('<div class="main-content">', unsafe_allow_html=True)
            self._render_home()
            st.markdown('</div>', unsafe_allow_html=True)

        with tab2:
            st.markdown('<div class="main-content">', unsafe_allow_html=True)
            self._render_search()
            st.markdown('</div>', unsafe_allow_html=True)

        with tab3:
            st.markdown('<div class="main-content">', unsafe_allow_html=True)
            self._render_settings()
            st.markdown('</div>', unsafe_allow_html=True)

        with tab4:
            st.markdown('<div class="main-content">', unsafe_allow_html=True)
            self._render_profile()
            st.markdown('</div>', unsafe_allow_html=True)

        # Sidebar
        with st.sidebar:
            st.title("Golden Sugar Daddy Goal")
            if st.button("üîë Logga in", key="login_button"):
                st.session_state["show_login"] = True

        # Modals
        if st.session_state.get("show_login"):
            self._show_login_modal()
        if st.session_state.get("selected_sponsor"):
            self._show_sponsor_modal(st.session_state["selected_sponsor"])

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ HOME ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    @staticmethod
    def _render_home() -> None:
        # Clean and professional layout
        col1, col2 = st.columns([1, 1])

        with col1:
            st.markdown(
                """
                <h2>V√§lkommen till Golden Sugar Daddy Goal</h2>
                <p style='font-size:1.1rem;line-height:1.6;margin-bottom:1.5rem;'>
                    Hitta de perfekta sponsorerna f√∂r din f√∂rening med hj√§lp av v√•r
                    avancerade matchmaking-plattform.
                </p>

                <div style='margin-top:2rem;'>
                    <h3>Hur det fungerar</h3>
                    <div style='display:flex;align-items:center;margin-bottom:1rem;'>
                        <div style='background:#1e40af;color:white;width:36px;height:36px;border-radius:50%;display:flex;align-items:center;justify-content:center;margin-right:16px;font-weight:bold;'>1</div>
                        <p>Registrera din f√∂rening eller hitta den i v√•r databas</p>
                    </div>
                    <div style='display:flex;align-items:center;margin-bottom:1rem;'>
                        <div style='background:#1e40af;color:white;width:36px;height:36px;border-radius:50%;display:flex;align-items:center;justify-content:center;margin-right:16px;font-weight:bold;'>2</div>
                        <p>Ange dina sponsringsbehov och preferenser</p>
                    </div>
                    <div style='display:flex;align-items:center;margin-bottom:1rem;'>
                        <div style='background:#1e40af;color:white;width:36px;height:36px;border-radius:50%;display:flex;align-items:center;justify-content:center;margin-right:16px;font-weight:bold;'>3</div>
                        <p>F√• matchningar med f√∂retag som passar din profil</p>
                    </div>
                </div>
                """,
                unsafe_allow_html=True
            )

        with col2:
            st.markdown(
                """
                <div style='background:#f0f9ff;border-radius:12px;padding:2rem;text-align:center;height:100%;'>
                    <img src="https://via.placeholder.com/150x150" alt="Logo" style="border-radius:50%;margin-bottom:1.5rem;width:150px;height:150px;box-shadow:0 4px 8px rgba(0,0,0,0.1);" />
                    <h3>Hitta sponsorer p√• ett smartare s√§tt</h3>
                    <p style='margin-bottom:2rem;'>V√•r plattform matchar din f√∂rening med sponsorer som har samma v√§rderingar och m√•l.</p>
                    <button 
                       style='background:#1e40af;color:white;padding:0.75rem 1.5rem;border-radius:8px;text-decoration:none;display:inline-block;font-weight:500;border:none;cursor:pointer;box-shadow:0 2px 4px rgba(0,0,0,0.1);'
                       onclick="document.querySelector('[data-baseweb=tab]').nextElementSibling.click();">
                        Kom ig√•ng nu
                    </button>
                </div>
                """,
                unsafe_allow_html=True
            )

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ SEARCH (with MAP) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def _render_search(self) -> None:
        st.markdown("<h2>Hitta sponsorer</h2>", unsafe_allow_html=True)

        # Create two columns for better layout
        col1, col2 = st.columns([3, 5], gap="large")

        with col1:
            # Load data from CSV instead of database connection
            associations_df = load_csv_data()

            # Step 1: Association Search with Autocomplete
            st.markdown("<h3>Steg 1: Hitta din f√∂rening</h3>", unsafe_allow_html=True)

            # Create association autocomplete
            association_input = st.text_input("Ange din f√∂renings namn", key="association_name")

            # Filter associations based on input
            filtered_associations = pd.DataFrame()
            if association_input:
                filtered_associations = associations_df[
                    associations_df['name'].str.contains(association_input, case=False)]

            # Display matching associations
            selected_association = None
            new_association = False

            if not filtered_associations.empty:
                association_options = filtered_associations['name'].tolist()
                selected_assoc_name = st.selectbox("V√§lj din f√∂rening fr√•n listan", options=[""] + association_options,
                                                   key="selected_assoc")

                if selected_assoc_name:
                    # FIX: Added proper error handling for DataFrame access
                    filtered_result = filtered_associations[filtered_associations['name'] == selected_assoc_name]
                    if not filtered_result.empty:
                        # Now we can safely use .iloc[0]
                        selected_association = filtered_result.iloc[0]

                        # Display association details
                        st.markdown(f"""
                        <div class="content-card">
                            <h4 style="margin-top:0;color:#1e40af;">F√∂rening: {selected_association['name']}</h4>
                            <p>Adress: {selected_association['address']}</p>
                            <p>Storlek: {selected_association['size_bucket'].capitalize()}</p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.warning("Ingen exakt matchning hittades")
            else:
                if association_input:
                    st.warning("Din f√∂rening hittades inte. Vill du registrera den?")
                    if st.button("Ja, registrera min f√∂rening"):
                        new_association = True

            # Step 2: New Association Registration (if needed)
            if new_association:
                st.markdown("<h3>Steg 2: Registrera din f√∂rening</h3>", unsafe_allow_html=True)
                with st.form("new_association_form"):
                    assoc_name = st.text_input("F√∂reningens namn", value=association_input)
                    assoc_address = st.text_input("Fullst√§ndig adress", help="Gatuadress, postnummer och ort")
                    assoc_members = st.number_input("Antal medlemmar", min_value=1, value=100)

                    # Determine size bucket based on members
                    size_bucket = "small"
                    if assoc_members > 500:
                        size_bucket = "large"
                    elif assoc_members > 100:
                        size_bucket = "medium"

                    st.info(f"Din f√∂rening klassificeras som {size_bucket.upper()} baserat p√• medlemsantalet.")

                    submit = st.form_submit_button("Registrera")

                    if submit:
                        # Geocode the address
                        from geopy.geocoders import Nominatim
                        from geopy.extra.rate_limiter import RateLimiter

                        geolocator = Nominatim(user_agent="sponsor_match_geo")
                        geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

                        with st.spinner('H√§mtar din f√∂renings plats...'):
                            location = geocode(assoc_address)

                        if location:
                            lat, lon = location.latitude, location.longitude

                            # Instead of inserting into database, create a new association object
                            selected_association = {
                                "id": len(associations_df) + 1,
                                "name": assoc_name,
                                "member_count": int(assoc_members),
                                "address": assoc_address,
                                "lat": float(lat),
                                "lon": float(lon),
                                "size_bucket": str(size_bucket)
                            }
                            st.success("F√∂rening registrerad!")
                        else:
                            st.error("Kunde inte hitta adressen. Kontrollera och f√∂rs√∂k igen.")

            # Step 3: Search Parameters
            if selected_association is not None:
                st.markdown("<h3>Steg 3: S√∂kparametrar</h3>", unsafe_allow_html=True)

                radius = st.slider("S√∂kradie (km)", 1, 50, 10, key="search_radius")

                # Store association in session state
                st.session_state["current_association"] = selected_association

                # Search button
                if st.button("S√∂k sponsorer", key="search_sponsors_btn"):
                    # Instead of searching database, generate dummy companies
                    with st.spinner('S√∂ker efter l√§mpliga sponsorer...'):
                        # Generate mock companies based on the selected association
                        companies = self._generate_mock_companies(selected_association, radius)

                        # Save results to session state
                        if companies:
                            st.session_state["search_results"] = companies
                            st.session_state["current_page"] = 0
                        else:
                            st.warning("Inga matchande f√∂retag hittades inom den angivna radien.")
                            st.session_state["search_results"] = []

        with col2:
            # Map section header
            st.markdown("<h3>Karta √∂ver sponsorer</h3>", unsafe_allow_html=True)

            # Always show map, either with selected association or default view of Sweden
            if "current_association" in st.session_state and st.session_state.get("search_results"):
                # Show map with search results
                page_size = 10
                current_page = st.session_state.get("current_page", 0)
                results = st.session_state["search_results"]
                start_idx = current_page * page_size
                end_idx = min(start_idx + page_size, len(results))
                page_results = results[start_idx:end_idx]

                self._render_results_map(st.session_state["current_association"], page_results)

                # Show pagination and results below map
                if results:
                    total_pages = max(1, (len(results) + page_size - 1) // page_size)

                    # Display page navigation
                    cols = st.columns([2, 3, 2])

                    with cols[0]:
                        if current_page > 0:
                            if st.button("‚óÄ F√∂reg√•ende", key="prev_page"):
                                st.session_state["current_page"] = current_page - 1
                                st.experimental_rerun()

                    with cols[1]:
                        st.markdown(f"<p style='text-align:center'>Sida {current_page + 1} av {total_pages}</p>",
                                    unsafe_allow_html=True)

                    with cols[2]:
                        if current_page < total_pages - 1:
                            if st.button("N√§sta ‚ñ∂", key="next_page"):
                                st.session_state["current_page"] = current_page + 1
                                st.experimental_rerun()

                    # Show result cards
                    for company in page_results:
                        is_selected = st.session_state.get("selected_company_id") == company["id"]

                        # Create a visually appealing company card
                        st.markdown(f"""
                        <div class="company-card {'selected' if is_selected else ''}" 
                             onclick="selectCompany({company['id']})">
                            <div style="font-weight:600;color:#1e40af;font-size:1.1rem;margin-bottom:0.5rem;">
                                {company['name']}
                            </div>
                            <div style="display:flex;justify-content:space-between;color:#4b5563;">
                                <div>Avst√•nd: {company['distance']:.1f} km</div>
                                <div>Storlek: {company['size_bucket'].capitalize()}</div>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)

                    # JavaScript to handle company selection
                    st.markdown("""
                    <script>
                    function selectCompany(id) {
                        window.parent.postMessage({
                            type: "streamlit:setComponentValue",
                            value: id,
                            dataType: "int",
                            componentId: "selected_company_id"
                        }, "*");
                    }
                    </script>
                    """, unsafe_allow_html=True)

                    # Hidden input to capture selected company
                    selected_id = st.text_input("", key="selected_company_id", label_visibility="collapsed")
                    if selected_id and selected_id != st.session_state.get("selected_company_id"):
                        st.session_state["selected_company_id"] = int(selected_id)
                        # Find the selected company and store it
                        selected_company = next((c for c in results if c["id"] == int(selected_id)), None)
                        if selected_company:
                            st.session_state["selected_sponsor"] = selected_company
                        st.experimental_rerun()

            else:
                # Show default map centered on Sweden
                default_association = {
                    "lat": 59.3293,
                    "lon": 18.0686,
                    "name": "Sverige",
                    "size_bucket": "medium"
                }
                self._render_results_map(default_association, [])

                # Show helper text when no search has been performed
                st.markdown("""
                <div style="text-align:center;padding:1.5rem;background:#f8fafc;border-radius:8px;margin-top:1rem;border:1px solid #e2e8f0;">
                    <p style="margin-bottom:1rem;">V√§lj din f√∂rening och klicka p√• "S√∂k sponsorer" f√∂r att se matchande sponsorer p√• kartan.</p>
                    <svg xmlns="http://www.w3.org/2000/svg" width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="#93c5fd" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <circle cx="11" cy="11" r="8"></circle>
                        <line x1="21" y1="21" x2="16.65" y2="16.65"></line>
                    </svg>
                </div>
                """, unsafe_allow_html=True)

    # Generate mock companies for testing
    @staticmethod
    def _generate_mock_companies(association, radius):
        """Generate mock companies around the selected association's location"""
        import random
        import numpy as np

        # Extract association location
        base_lat = float(association["lat"])
        base_lon = float(association["lon"])

        # Company names for testing
        company_names = [
            "Nordea Bank", "Volvo Group", "Ericsson AB", "IKEA G√∂teborg",
            "H&M Retail", "SEB Bank", "Handelsbanken", "ICA Supermarket",
            "Telia Company", "Elekta AB", "Atlas Copco", "SKF Group",
            "Sandvik AB", "Systembolaget", "Circle K", "Stadium Sports",
            "Max Burgers", "√Öhl√©ns", "Clas Ohlson", "Nordnet Bank"
        ]

        # Size buckets with same distribution as association size
        size_buckets = ["small", "medium", "large"]
        size_weights = {"small": 0.2, "medium": 0.5, "large": 0.3}

        # Generate 5-15 companies
        num_companies = random.randint(5, 15)
        companies = []

        for i in range(num_companies):
            # Generate random distance within radius (km)
            distance = random.uniform(0.5, radius)

            # Generate random direction (angle in radians)
            angle = random.uniform(0, 2 * np.pi)

            # Calculate new coordinates (rough approximation)
            # 111.32 km = 1 degree latitude
            # 111.32 * cos(latitude) km = 1 degree longitude
            lat_offset = distance / 111.32 * np.cos(angle)
            lon_offset = distance / (111.32 * np.cos(np.radians(base_lat))) * np.sin(angle)

            new_lat = base_lat + lat_offset
            new_lon = base_lon + lon_offset

            # Assign company size - match with association size for better matches
            # but include some variety
            if random.random() < 0.7:  # 70% chance to match association size
                size_bucket = association["size_bucket"]
            else:
                # Random size from distribution
                size_bucket = random.choices(size_buckets,
                                             weights=[size_weights["small"],
                                                      size_weights["medium"],
                                                      size_weights["large"]])[0]

            # Create company object
            company = {
                "id": i + 1,
                "name": company_names[i % len(company_names)],
                "description": f"Ett {size_bucket} f√∂retag inom {random.choice(['teknologi', 'finans', 'handel', 'tillverkning', 'tj√§nster'])}.",
                "lat": new_lat,
                "lon": new_lon,
                "distance": distance,
                "size_bucket": size_bucket,
                "score": random.randint(40, 95),
                "contact": {
                    "email": f"kontakt@{company_names[i % len(company_names)].lower().replace(' ', '')}.se",
                    "phone": f"0{random.randint(7, 8)}-{random.randint(100, 999)} {random.randint(10, 99)} {random.randint(10, 99)}"
                }
            }

            companies.append(company)

        # Sort by distance
        companies.sort(key=lambda x: x["distance"])

        return companies

    # Add new method to render results map
    @staticmethod
    def _render_results_map(association, companies):
        import folium
        from streamlit_folium import st_folium

        # Create map centered on association
        try:
            # FIX: Ensure proper type conversion for map coordinates
            lat = float(association["lat"])
            lon = float(association["lon"])
            m = folium.Map(location=[lat, lon], zoom_start=12)

            # Add association marker
            folium.Marker(
                location=[lat, lon],
                popup=f"<b>{association['name']}</b><br>({association['size_bucket'].capitalize()})",
                icon=folium.Icon(color="red", icon="home"),
            ).add_to(m)

            # Add markers for each company
            for company in companies:
                try:
                    comp_lat = float(company["lat"])
                    comp_lon = float(company["lon"])
                    folium.Marker(
                        location=[comp_lat, comp_lon],
                        popup=f"<b>{company['name']}</b><br>Avst√•nd: {company['distance']:.1f} km<br>Storlek: {company['size_bucket'].capitalize()}",
                        icon=folium.Icon(color="blue", icon="briefcase"),
                    ).add_to(m)
                except (KeyError, ValueError, TypeError):
                    # Skip this company if there's an issue with its coordinates
                    continue

            # Create a line from association to selected company if any
            if "selected_company_id" in st.session_state:
                # FIX: Use safe lookup with next() and a default value
                selected = next((c for c in companies if c["id"] == st.session_state["selected_company_id"]), None)
                if selected:  # Only proceed if we found a matching company
                    try:
                        folium.PolyLine(
                            locations=[[lat, lon], [float(selected["lat"]), float(selected["lon"])]],
                            color="#1e40af",
                            weight=3,
                            opacity=0.7,
                            dash_array="5"
                        ).add_to(m)
                    except (KeyError, ValueError, TypeError):
                        # Skip drawing line if there's an issue
                        pass

            # Display the map
            st_folium(m, height=500)
        except Exception as e:
            st.error(f"Kunde inte visa kartan: {str(e)}")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ SETTINGS PAGE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    @staticmethod
    def _render_settings() -> None:
        st.markdown("<h2>Inst√§llningar</h2>", unsafe_allow_html=True)

        # Use columns for better layout
        col1, col2 = st.columns(2, gap="large")

        with col1:
            st.markdown('<div class="content-card">', unsafe_allow_html=True)
            st.markdown("<h3>Notifikationer</h3>", unsafe_allow_html=True)
            st.checkbox("E-postnotifikationer", value=True)
            st.checkbox("Sponsringsrekommendationer", value=True)
            st.markdown('</div>', unsafe_allow_html=True)

            st.markdown('<div class="content-card">', unsafe_allow_html=True)
            st.markdown("<h3>Datainst√§llningar</h3>", unsafe_allow_html=True)
            st.checkbox("Spara s√∂khistorik", value=True)
            st.checkbox("Till√•t anonym anv√§ndardata", value=True)
            st.markdown('</div>', unsafe_allow_html=True)

        with col2:
            st.markdown('<div class="content-card">', unsafe_allow_html=True)
            st.markdown("<h3>Visningsalternativ</h3>", unsafe_allow_html=True)
            st.markdown("<p>Resultat per sida</p>", unsafe_allow_html=True)
            st.select_slider(
                "Antal resultat",
                options=[5, 10, 15, 20, 25],
                value=15,
                key="results_per_page",
                label_visibility="collapsed"
            )

            st.markdown("<p>Kartdetaljniv√•</p>", unsafe_allow_html=True)
            st.select_slider(
                "Detaljniv√•",
                options=["L√•g", "Medium", "H√∂g"],
                value="Medium",
                key="map_detail_level",
                label_visibility="collapsed"
            )
            st.markdown('</div>', unsafe_allow_html=True)

        # Add save button at the bottom
        st.markdown('<div style="text-align:center;margin-top:2rem;">', unsafe_allow_html=True)
        if st.button("Spara inst√§llningar", key="save_settings"):
            st.success("Inst√§llningarna har sparats!")
        st.markdown('</div>', unsafe_allow_html=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PROFILE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    @staticmethod
    def _render_profile() -> None:
        st.markdown("<h2>Min f√∂rening</h2>", unsafe_allow_html=True)

        st.markdown('<div class="content-card">', unsafe_allow_html=True)

        # Use columns for form layout
        col1, col2 = st.columns(2, gap="medium")

        with col1:
            st.text_input("F√∂reningens namn", value="", key="profile_name")
            st.text_input("Ort", value="", key="profile_city")

        with col2:
            st.text_input("E-post", value="", key="profile_email")
            st.text_input("Telefon", value="", key="profile_phone")

        # Full width for sponsorship needs
        st.text_area("Sponsringsbehov", value="", key="profile_needs", height=150)

        # Add save button
        st.markdown('<div style="text-align:center;margin-top:1.5rem;">', unsafe_allow_html=True)
        if st.button("Spara", key="save_profile"):
            st.success("Profilen har sparats!")
        st.markdown('</div>', unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MODALS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    @staticmethod
    def _show_login_modal() -> None:
        with _open_modal("Logga in"):
            st.markdown('<div style="padding:1rem;">', unsafe_allow_html=True)
            st.text_input("E-post", value="", key="login_email")
            st.text_input("L√∂senord", value="", type="password", key="login_pw")

            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("Logga in", key="login_submit"):
                    st.session_state["show_login"] = False
            with col2:
                if st.button("Avbryt", key="login_cancel"):
                    st.session_state["show_login"] = False
            st.markdown('</div>', unsafe_allow_html=True)

    @staticmethod
    def _show_sponsor_modal(sponsor: Dict[str, Any]) -> None:
        # FIX: Added safety check for sponsor structure
        if not isinstance(sponsor, dict):
            st.error("Ogiltig sponsor-data")
            return

        with _open_modal(sponsor.get("name", "Sponsor")):
            st.markdown('<div style="padding:1rem;">', unsafe_allow_html=True)

            # Company details
            st.markdown(f"""
            <div style="margin-bottom:1.5rem;">
                <p style="font-size:1rem;">{sponsor.get("description", "")}</p>
            </div>
            """, unsafe_allow_html=True)

            # Contact information
            contact = sponsor.get("contact", {})
            st.markdown(f"""
            <div style="margin-bottom:1.5rem;">
                <h4 style="margin-bottom:0.5rem;">Kontaktuppgifter</h4>
                <p><strong>E-post:</strong> {contact.get('email', 'N/A')}</p>
                <p><strong>Telefon:</strong> {contact.get('phone', 'N/A')}</p>
            </div>
            """, unsafe_allow_html=True)

            # Message form
            st.markdown("<h4>Skicka meddelande</h4>", unsafe_allow_html=True)
            st.text_area("Meddelande", value="", key="msg_to_sponsor", height=150)

            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("Skicka", key="msg_submit"):
                    st.success("Meddelande skickat!")
                    st.session_state["selected_sponsor"] = None
            with col2:
                if st.button("Avbryt", key="msg_cancel"):
                    st.session_state["selected_sponsor"] = None

            st.markdown('</div>', unsafe_allow_html=True)


def main() -> None:
    SponsorMatchUI().render_main_page()


if __name__ == "__main__":
    main()

================================================================================
FIL: .streamlit/config.toml
================================================================================

[theme]
primaryColor           = "#1e40af"
backgroundColor        = "#f9fafb"
secondaryBackgroundColor = "#ffffff"
textColor              = "#111827"
font                   = "sans serif"


================================================================================
FIL: .streamlit/secrets.toml
================================================================================

[mysql]
user         = "sponsor_user"
password     = "Sports-2025?!"
host         = "localhost"
port         = "3306"
database     = "sponsor_registry"
# optional override URL
url_override = "mysql+mysqlconnector://sponsor_user:Sports-2025?!@localhost:3306/sponsor_registry"


================================================================================
FIL: sponsor_match/__init__.py
================================================================================

#!/usr/bin/env python3
"""
SponsorMatch AI package.

Expose subpackages and provide package version information.
"""

from importlib.metadata import version, PackageNotFoundError

try:
    __version__ = version("sponsor_match")
except PackageNotFoundError:
    __version__ = "0.0.0"

__all__ = [
    "core",
    "data",
    "models",
    "services",
    "ui",
]


================================================================================
FIL: sponsor_match/services/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/services/service.py
================================================================================

import logging
from typing import Dict, Optional

import pandas as pd
from sqlalchemy.orm import sessionmaker

from sponsor_match.core.config import LOG_LEVEL
from sponsor_match.models.entities import Association, Company, Base

logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format="%(asctime)s %(levelname)s %(message)s"
)
logger = logging.getLogger(__name__)


class SponsorMatchService:
    """Main service class for sponsor matching operations."""

    def __init__(self, db_engine):
        """Initialize service with database engine."""
        self.engine = db_engine
        self.Session = sessionmaker(bind=db_engine)

        # Ensure tables exist
        Base.metadata.create_all(bind=db_engine)

    def search(self, query: str, limit: int = 100) -> pd.DataFrame:
        """Search both associations and companies by name."""
        with self.Session() as session:
            # Search associations
            associations = session.query(
                Association.id,
                Association.name,
                Association.address,
                Association.lat.label('latitude'),
                Association.lon.label('longitude')
            ).filter(
                Association.name.ilike(f'%{query}%')
            ).limit(limit // 2).all()

            # Search companies
            companies = session.query(
                Company.id,
                Company.name,
                Company.lat.label('latitude'),
                Company.lon.label('longitude')
            ).filter(
                Company.name.ilike(f'%{query}%')
            ).limit(limit // 2).all()

        # Convert to DataFrame
        results = []
        for assoc in associations:
            results.append({
                'type': 'association',
                'id': assoc.id,
                'name': assoc.name,
                'address': assoc.address,
                'latitude': assoc.latitude,
                'longitude': assoc.longitude
            })

        for comp in companies:
            results.append({
                'type': 'company',
                'id': comp.id,
                'name': comp.name,
                'address': None,
                'latitude': comp.latitude,
                'longitude': comp.longitude
            })

        return pd.DataFrame(results)

    def get_association_by_name(self, name: str) -> Optional[Dict]:
        """Get association details by name."""
        with self.Session() as session:
            assoc = session.query(Association).filter(
                Association.name == name
            ).first()

            if assoc:
                return {
                    'id': assoc.id,
                    'name': assoc.name,
                    'lat': assoc.lat,
                    'lon': assoc.lon,
                    'size_bucket': assoc.size_bucket,
                    'member_count': assoc.member_count,
                    'address': assoc.address
                }
        return None

    def get_companies_for_matching(self) -> pd.DataFrame:
        """Get all companies with coordinates for matching."""
        with self.Session() as session:
            companies = session.query(Company).filter(
                Company.lat.isnot(None),
                Company.lon.isnot(None)
            ).all()

        data = []
        for comp in companies:
            data.append({
                'id': comp.id,
                'name': comp.name,
                'lat': comp.lat,
                'lon': comp.lon,
                'size_bucket': comp.size_bucket,
                'revenue_ksek': comp.revenue_ksek,
                'employees': comp.employees,
                'industry': comp.industry
            })

        return pd.DataFrame(data)

    def recommend(self, association_name: str, top_n: int = 10) -> pd.DataFrame:
        """Simple distance-based recommendations."""
        # Get association
        assoc = self.get_association_by_name(association_name)
        if not assoc:
            logger.warning(f"No association found matching '{association_name}'")
            return pd.DataFrame()

        # Get companies
        companies_df = self.get_companies_for_matching()
        if companies_df.empty:
            logger.info("No companies found.")
            return pd.DataFrame()

        # Calculate distances (simple Euclidean for now)
        lat, lon = assoc['lat'], assoc['lon']
        companies_df["distance"] = (
                                           (companies_df["lat"] - lat) ** 2 +
                                           (companies_df["lon"] - lon) ** 2
                                   ) ** 0.5

        return companies_df.sort_values("distance").head(top_n).reset_index(drop=True)


# Module-level functions for backward compatibility
_service_instance = None


def get_service(engine):
    """Get or create service instance."""
    global _service_instance
    if _service_instance is None:
        _service_instance = SponsorMatchService(engine)
    return _service_instance


def search(engine, query: str) -> pd.DataFrame:
    """Search wrapper for backward compatibility."""
    service = get_service(engine)
    return service.search(query)


def recommend(engine, association_name: str, top_n: int = 10) -> pd.DataFrame:
    """Recommend wrapper for backward compatibility."""
    service = get_service(engine)
    return service.recommend(association_name, top_n)

================================================================================
FIL: sponsor_match/cli/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/cli/db_init.py
================================================================================

#!/usr/bin/env python3
"""
sponsor_match/db_init.py
------------------------
Create (if needed) the `associations` and `companies` tables in MySQL.

Usage:
    python -m sponsor_match.db_init
"""

import logging
from argparse import ArgumentParser
from textwrap import dedent
from sponsor_match.core.db import get_engine

# Configure logging
logging.basicConfig(
    format="%(asctime)s %(levelname)s %(name)s: %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

DDL = dedent("""
   CREATE TABLE IF NOT EXISTS associations (
        id             INT PRIMARY KEY AUTO_INCREMENT,
        name           VARCHAR(120),
        member_count   INT,
        address        TEXT,
        lat            DOUBLE,
        lon            DOUBLE,
        size_bucket    ENUM('small','medium','large'),
        founded_year   INT
   ) CHARACTER SET utf8mb4;

   CREATE TABLE IF NOT EXISTS companies (
       id           INT AUTO_INCREMENT PRIMARY KEY,
       orgnr        CHAR(10),
       name         VARCHAR(200),
       revenue_ksek DOUBLE,
       employees    INT,
       year         INT,
       size_bucket  ENUM('small','medium','large'),
       industry     VARCHAR(120),
       lat          DOUBLE,
       lon          DOUBLE
   ) CHARACTER SET utf8mb4;
""")


def main(dry_run: bool = False) -> None:
    """
    Execute the DDL statements to ensure tables exist.
    If dry_run is True, only logs the statements without executing.
    """
    engine = get_engine()
    logger.info("Connecting to database")
    if dry_run:
        logger.info("Dry run mode: the following statements would be executed:\n%s", DDL)
        return

    try:
        with engine.begin() as conn:
            for stmt in DDL.strip().split(";"):
                stmt = stmt.strip()
                if not stmt:
                    continue
                conn.exec_driver_sql(stmt)
                logger.info("Executed DDL: %s", stmt.splitlines()[0])
        logger.info("‚úÖ Tables `associations` and `companies` are ready")
    except Exception as e:
        logger.exception("Database initialization failed: %s", e)
        raise


if __name__ == "__main__":
    parser = ArgumentParser(description="Initialize MySQL tables for SponsorMatch")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show DDL without executing"
    )
    args = parser.parse_args()
    main(dry_run=args.dry_run)

================================================================================
FIL: sponsor_match/cli/run_pipeline.py
================================================================================

import argparse
import json
from sponsor_match.ml.pipeline import score_and_rank

def main():
    parser = argparse.ArgumentParser(
        description="Batch-run sponsor recommendations for one association"
    )
    parser.add_argument("--assoc-id", type=int, required=True)
    parser.add_argument("--bucket",    choices=["small","medium","large"], required=True)
    parser.add_argument("--max-distance", type=float, default=50.0)
    parser.add_argument("--top-n",      type=int, default=10)
    parser.add_argument("--output",     type=str, required=True)
    args = parser.parse_args()

    recs = score_and_rank(
        association_id=args.assoc_id,
        bucket=args.bucket,
        max_distance=args.max_distance,
        top_n=args.top_n
    )

    with open(args.output, "w") as f:
        json.dump(recs, f, indent=2)
    print(f"Wrote {len(recs)} recommendations to {args.output}")

if __name__ == "__main__":
    main()


================================================================================
FIL: sponsor_match/cli/train_matcher.py
================================================================================

#!/usr/bin/env python3
"""
cli/train_matcher.py
---------------------
Train a GradientBoostingClassifier on labeled sponsor‚Äìclub pairs
and save the model artifact under the project's `models/` directory.

Usage:
    python cli/train_matcher.py \
      --input data/positive_pairs.parquet \
      --test-size 0.2 \
      --random-state 1
"""

import logging
from argparse import ArgumentParser
from pathlib import Path

import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier

from sponsor_match.models.features import FeatureEngineer

# configure logging
logging.basicConfig(
    format="%(asctime)s %(levelname)s %(name)s: %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Determine project root and models directory
PROJECT_ROOT = Path(__file__).resolve().parents[1]  # cli/ -> project root
DEFAULT_MODEL_DIR = PROJECT_ROOT / "models"

def main(
    input_path: Path,
    model_dir: Path,
    test_size: float,
    random_state: int
) -> None:
    """
    Load training data, engineer features, split into train/validation,
    train a GradientBoostingClassifier, evaluate, and save the model.

    Parameters
    ----------
    input_path : Path
        Parquet file of labeled club‚Äìcompany pairs with a 'label' column.
    model_dir : Path
        Directory in which to save the trained model artifact.
    test_size : float
        Fraction of data reserved for validation.
    random_state : int
        Seed for reproducible splits.
    """
    logger.info("Loading data from %s", input_path)
    df = pd.read_parquet(input_path)
    logger.info("Loaded %d rows", len(df))

    logger.info("Generating pairwise features")
    X = FeatureEngineer.make_pair_features(df)
    y = df["label"]

    logger.info(
        "Splitting into train/validation (test_size=%.2f, random_state=%d)",
        test_size, random_state
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )

    logger.info("Training GradientBoostingClassifier")
    clf = GradientBoostingClassifier(random_state=random_state)
    clf.fit(X_train, y_train)

    val_acc = clf.score(X_val, y_val)
    logger.info("Validation accuracy: %.4f", val_acc)

    # Ensure the models directory exists
    model_dir.mkdir(parents=True, exist_ok=True)
    model_path = model_dir / "match_gb.joblib"

    logger.info("Saving trained model to %s", model_path)
    joblib.dump(clf, model_path)
    logger.info("Done.")

if __name__ == "__main__":
    parser = ArgumentParser(description="Train the sponsor‚Äìclub matching classifier")
    parser.add_argument(
        "--input",
        type=Path,
        default=Path("data/positive_pairs.parquet"),
        help="Parquet file of labeled pairs"
    )
    parser.add_argument(
        "--model-dir",
        type=Path,
        default=DEFAULT_MODEL_DIR,
        help="Directory for saving model artifacts"
    )
    parser.add_argument(
        "--test-size",
        type=float,
        default=0.2,
        help="Fraction of data for validation"
    )
    parser.add_argument(
        "--random-state",
        type=int,
        default=1,
        help="Seed for train/validation split"
    )

    args = parser.parse_args()
    main(
        input_path=args.input,
        model_dir=args.model_dir,
        test_size=args.test_size,
        random_state=args.random_state
    )


================================================================================
FIL: sponsor_match/ui/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/ui/app.py
================================================================================

import streamlit as st
from pathlib import Path
import logging

from sponsor_match.core.config import APP_TITLE, LOGO_PATH, STREAMLIT_PAGE_ICON
from sponsor_match.ui.styles import apply_professional_styles
from sponsor_match.ui.pages.home import render_home_page
from sponsor_match.ui.pages.search import render_search_page
from sponsor_match.ui.pages.profile import render_profile_page


def set_page_config():
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon=STREAMLIT_PAGE_ICON,
        layout="wide",
        initial_sidebar_state="expanded",
    )


def main():
    set_page_config()
    apply_professional_styles()

    # Header
    col1, col2 = st.columns([4, 1])
    with col1:
        st.title("üèÜ SponsorMatch AI")
        st.markdown("*Find the perfect sponsors for your sports club*")

    with col2:
        logo_path = Path(LOGO_PATH)
        if logo_path.exists():
            try:
                st.image(str(logo_path), width=100)
            except Exception:
                pass

    # Navigation
    tab1, tab2, tab3 = st.tabs(["üè† Home", "üîç Find Sponsors", "üë§ My Club"])

    with tab1:
        render_home_page()
    with tab2:
        render_search_page()
    with tab3:
        render_profile_page()


if __name__ == "__main__":
    main()


