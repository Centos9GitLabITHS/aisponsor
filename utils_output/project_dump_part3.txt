================================================================================
FIL: sponsor_match/ui/styles.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

import streamlit as st


def apply_professional_styles():
    """Apply professional styling to Streamlit app."""
    css = """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

    /* Main app styling */
    .main .block-container {
        font-family: 'Inter', sans-serif;
        padding-top: 1rem;
        padding-bottom: 2rem;
        max-width: 1200px;
    }

    /* Header styling */
    h1 {
        color: #1e40af !important;
        font-weight: 700 !important;
        margin-bottom: 2rem !important;
    }

    h2 {
        color: #1e40af !important;
        font-weight: 600 !important;
        margin-bottom: 1.5rem !important;
    }

    /* Button styling */
    .stButton > button {
        background-color: #2563eb;
        color: white;
        border-radius: 8px;
        font-weight: 500;
        border: none;
        padding: 0.5rem 1rem;
        transition: all 0.2s ease;
    }

    .stButton > button:hover {
        background-color: #1d4ed8;
        box-shadow: 0 2px 8px rgba(37, 99, 235, 0.3);
        transform: translateY(-1px);
    }

    /* Metric cards */
    [data-testid="metric-container"] {
        background: white;
        border: 1px solid #e2e8f0;
        border-radius: 8px;
        padding: 1rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
    }

    /* Sidebar styling */
    .css-1d391kg {
        background-color: #f8fafc;
    }

    /* Input fields */
    .stTextInput > div > div > input {
        border-radius: 6px;
        border: 1px solid #d1d5db;
    }

    .stTextInput > div > div > input:focus {
        border-color: #2563eb;
        box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.1);
    }

    /* Success/Error styling */
    .stSuccess {
        background-color: #f0f9ff;
        border-left: 4px solid #10b981;
    }

    .stError {
        background-color: #fef2f2;
        border-left: 4px solid #ef4444;
    }
    </style>
    """
    st.markdown(css, unsafe_allow_html=True)


def create_metric_card(title, value, delta=None):
    """Create a styled metric card."""
    delta_html = ""
    if delta:
        color = "#10b981" if delta > 0 else "#ef4444"
        arrow = "‚Üó" if delta > 0 else "‚Üò"
        delta_html = f"""
        <div style="color: {color}; font-size: 0.875rem; font-weight: 500;">
            {arrow} {abs(delta):.1f}%
        </div>
        """

    return f"""
    <div style="background: white; border: 1px solid #e2e8f0; border-radius: 8px; 
                padding: 1.5rem; box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);">
        <div style="color: #6b7280; font-size: 0.875rem; margin-bottom: 0.5rem;">
            {title}
        </div>
        <div style="font-size: 1.875rem; font-weight: 700; color: #111827; margin-bottom: 0.25rem;">
            {value}
        </div>
        {delta_html}
    </div>
    """

================================================================================
FIL: sponsor_match/ui/services/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/ui/services/data_service.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

"""
Data service for handling data loading and initialization.
"""
import logging

import pandas as pd

from sponsor_match.core.db import get_engine
from sponsor_match.ui.utils.sessions import set_session_data

logger = logging.getLogger(__name__)

# Global caches
_engine = None
_clubs_df = None
_companies_df = None


def load_initial_data():
    """
    Load initial data needed by the application.
    This should be called once at startup.
    """
    try:
        # Initialize engine
        global _engine
        _engine = get_engine()
        logger.info("Database engine initialized")

        # Load clubs
        load_clubs()

        # Load only if needed in UI
        # load_companies()

        return True
    except Exception as e:
        logger.error(f"Error loading initial data: {e}")
        return False


def load_clubs():
    """
    Load clubs from database or use fallback data.

    Returns:
        DataFrame of clubs
    """
    global _clubs_df

    # Return cached data if available
    if _clubs_df is not None:
        return _clubs_df

    try:
        if _engine:
            _clubs_df = pd.read_sql("SELECT * FROM clubs", _engine)
            logger.info(f"Loaded {len(_clubs_df)} clubs from database")
            return _clubs_df
    except Exception as e:
        logger.warning(f"Failed to load clubs from database: {e}")

    # Create sample data as fallback
    _clubs_df = pd.DataFrame({
        'id': [1, 2, 3],
        'name': ['IFK G√∂teborg', 'GAIS', 'BK H√§cken'],
        'size_bucket': ['large', 'medium', 'medium'],
        'member_count': [500, 250, 300],
        'lat': [57.7089, 57.6969, 57.7209],
        'lon': [11.9746, 11.9789, 11.9390],
        'address': ['G√∂teborg', 'G√∂teborg', 'G√∂teborg']
    })
    logger.info("Using sample club data")

    return _clubs_df


def load_companies():
    """
    Load companies from database or use fallback data.

    Returns:
        DataFrame of companies
    """
    global _companies_df

    # Return cached data if available
    if _companies_df is not None:
        return _companies_df

    try:
        if _engine:
            _companies_df = pd.read_sql("SELECT * FROM companies", _engine)
            logger.info(f"Loaded {len(_companies_df)} companies from database")
            return _companies_df
    except Exception as e:
        logger.warning(f"Failed to load companies from database: {e}")

    # Create sample data as fallback
    _companies_df = pd.DataFrame([
        {
            "id": 1,
            "name": "Nordic Bank",
            "revenue_ksek": 50000,
            "employees": 120,
            "industry": "Finance",
            "size_bucket": "large",
            "lat": 57.70,
            "lon": 11.97
        },
        {
            "id": 2,
            "name": "Energigruppen AB",
            "revenue_ksek": 25000,
            "employees": 45,
            "industry": "Energy",
            "size_bucket": "medium",
            "lat": 57.71,
            "lon": 11.98
        }
    ])
    logger.info("Using sample company data")

    return _companies_df


def get_club_by_id(club_id):
    """
    Get a club by its ID.

    Args:
        club_id: Club ID to look up

    Returns:
        Club dictionary or None if not found
    """
    # Load clubs if needed
    clubs = load_clubs()

    # Find club by ID
    club_row = clubs[clubs['id'] == club_id]
    if len(club_row) > 0:
        return club_row.iloc[0].to_dict()

    return None


def save_club(club_data):
    """
    Save club data to database.
    This is a placeholder - in a real app, this would update the database.

    Args:
        club_data: Dictionary of club data to save

    Returns:
        True if successful, False otherwise
    """
    # In a real application, this would save to the database
    logger.info(f"Saving club data: {club_data}")

    # For now, just store in session state
    set_session_data("selected_club", club_data)

    # Pretend it was successful
    return True


================================================================================
FIL: sponsor_match/ui/services/search_services.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

from sponsor_match.ml.pipeline import score_and_rank

def recommend_sponsors(club_id: int, club_bucket: str,
                       max_distance: float = 50.0, top_n: int = 10):
    """
    Returns list of {id,name,lat,lon,distance,score} for top_n companies.
    """
    return score_and_rank(
        assoc_id=club_id,
        assoc_bucket=club_bucket,
        max_distance=max_distance,
        top_n=top_n
    )


================================================================================
FIL: sponsor_match/ui/components/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/ui/components/cards.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

"""
Card UI components for SponsorMatch application.
"""
import streamlit as st


def render_info_card(icon, title, text):
    """
    Render an information card with icon, title and text.

    Args:
        icon: Emoji or icon character
        title: Card title
        text: Card description text
    """
    st.markdown(
        f"""
        <div style="background:#eff6ff;border:1px solid #bfdbfe;border-radius:8px;
                    padding:1.5rem;text-align:center;box-shadow:0 1px 2px rgba(0,0,0,0.05);">
          <div style="font-size:2rem;color:#2563eb;margin-bottom:0.5rem;">{icon}</div>
          <div style="font-size:1.125rem;font-weight:600;color:#1e40af;margin-bottom:0.5rem;">{title}</div>
          <div style="font-size:0.875rem;color:#4b5563;">{text}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def render_sponsor_card(sponsor):
    """
    Render a sponsor card with company information and contact button.

    Args:
        sponsor: Dictionary containing sponsor information
    """
    # Extract sponsor details, with defaults for missing values
    name = sponsor.get('name', 'Unknown Sponsor')
    description = sponsor.get('description', 'No description available.')
    score = sponsor.get('score', 0)
    revenue = sponsor.get('revenue_ksek', 'N/A')
    employees = sponsor.get('employees', 'N/A')
    industry = sponsor.get('industry', 'N/A')

    # Format score as percentage
    score_display = f"{score:.0%}" if isinstance(score, (int, float)) else "N/A"

    # Create formatted card with all information
    st.markdown(
        f"""
        <div style="background:white;padding:1.5rem;border-radius:8px;
                    box-shadow:0 1px 3px rgba(0,0,0,0.1);margin-bottom:1rem;">
          <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:0.5rem;">
            <div style="font-size:1.125rem;font-weight:700;color:#1e40af;">{name}</div>
            <div style="background:#dbeafe;color:#1e40af;padding:0.25rem 0.5rem;
                        border-radius:9999px;font-size:0.75rem;font-weight:600;">
              {score_display} match
            </div>
          </div>
          <div style="font-size:0.875rem;color:#4b5563;margin-bottom:0.75rem;">{description}</div>
          <div style="display:grid;grid-template-columns:repeat(3,1fr);gap:0.5rem;
                      font-size:0.75rem;color:#6b7280;margin-bottom:1rem;">
            <div>
              <div style="font-weight:600;">Oms√§ttning</div>
              <div>{revenue} tkr</div>
            </div>
            <div>
              <div style="font-weight:600;">Anst√§llda</div>
              <div>{employees}</div>
            </div>
            <div>
              <div style="font-weight:600;">Bransch</div>
              <div>{industry}</div>
            </div>
          </div>
          <div style="display:flex;gap:0.5rem;">
            <button style="flex:1;background:#2563eb;color:white;padding:0.5rem 1rem;
                           border:none;border-radius:4px;font-weight:500;cursor:pointer;">
              üìß Kontakta
            </button>
            <button style="flex:1;background:#f3f4f6;color:#374151;padding:0.5rem 1rem;
                           border:none;border-radius:4px;font-weight:500;cursor:pointer;">
              ‚ÑπÔ∏è Detaljer
            </button>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def render_stat_card(title, value, description=None, trend=None):
    """
    Render a statistic card with optional trend indicator.

    Args:
        title: Stat title
        value: Main value to display
        description: Optional description or context
        trend: Optional trend value (positive or negative number)
    """
    # Determine trend styling
    trend_html = ""
    if trend is not None:
        trend_color = "#10b981" if trend > 0 else "#ef4444"  # Green or red
        trend_arrow = "‚Üë" if trend > 0 else "‚Üì"
        trend_html = f"""
        <div style="color:{trend_color};font-size:0.875rem;font-weight:600;">
          {trend_arrow} {abs(trend):.1f}%
        </div>
        """

    # Description HTML if provided
    desc_html = f"""
    <div style="color:#6b7280;font-size:0.75rem;">
      {description}
    </div>
    """ if description else ""

    # Render the card
    st.markdown(
        f"""
        <div style="background:white;padding:1.25rem;border-radius:8px;
                    box-shadow:0 1px 3px rgba(0,0,0,0.1);height:100%;">
          <div style="color:#6b7280;font-size:0.875rem;margin-bottom:0.5rem;">
            {title}
          </div>
          <div style="display:flex;align-items:baseline;gap:0.5rem;">
            <div style="font-size:1.5rem;font-weight:700;color:#111827;">
              {value}
            </div>
            {trend_html}
          </div>
          {desc_html}
        </div>
        """,
        unsafe_allow_html=True,
    )


================================================================================
FIL: sponsor_match/ui/components/map_view.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

# sponsor_match/ui/components/map_view.py

from folium import Map, Marker, Popup, Icon
from folium.plugins import MarkerCluster, HeatMap
from streamlit_folium import st_folium

def render_map(club=None, sponsors=None, height=400, width=None):
    """
    Render an interactive map with club and sponsor markers.

    Args:
        club: Dictionary with club information (optional)
        sponsors: List of sponsor dictionaries (optional)
        height: Map height in pixels (default 400)
        width:  Map width in pixels (optional; omit to auto-size)
    """
    # Default center on Gothenburg
    center = [57.7089, 11.9746]
    if club and club.get('lat') and club.get('lon'):
        center = [club['lat'], club['lon']]

    m = Map(location=center, zoom_start=12, tiles="CartoDB positron")

    # Club marker
    if club and club.get('lat') and club.get('lon'):
        Marker(
            location=[club['lat'], club['lon']],
            popup=Popup(_club_popup(club), max_width=300),
            icon=Icon(color='purple', icon='flag', prefix='fa'),
            tooltip=club.get('name', 'Club')
        ).add_to(m)

    # Sponsor markers
    if sponsors:
        cluster = MarkerCluster().add_to(m)
        heat_data = []
        for sponsor in sponsors:
            if sponsor.get('lat') and sponsor.get('lon'):
                Marker(
                    location=[sponsor['lat'], sponsor['lon']],
                    popup=Popup(_sponsor_popup(sponsor), max_width=300),
                    icon=Icon(color=_marker_color(sponsor), icon='building', prefix='fa'),
                    tooltip=sponsor.get('name', 'Sponsor')
                ).add_to(cluster)
                if sponsor.get('score') is not None:
                    heat_data.append([sponsor['lat'], sponsor['lon'], sponsor['score']])
        if heat_data:
            HeatMap(heat_data).add_to(m)

    # Only pass width if it‚Äôs a real integer
    if width:
        return st_folium(m, width=width, height=height)
    else:
        return st_folium(m, height=height)


def _club_popup(club):
    return f"""
    <div style="width:200px">
        <h4>{club.get('name','')}</h4>
        <p><b>Medlemmar:</b> {club.get('member_count','N/A')}</p>
        <p><b>Storlek:</b> {club.get('size_bucket','').title()}</p>
        <p><b>Adress:</b> {club.get('address','N/A')}</p>
    </div>
    """

def _sponsor_popup(sponsor):
    contact = sponsor.get('contact', {})
    return f"""
    <div style="width:200px">
        <h4>{sponsor.get('name','')}</h4>
        <p>{sponsor.get('description','')}</p>
        <p>üìß {contact.get('email','')}</p>
        <p>üìû {contact.get('phone','')}</p>
    </div>
    """

def _marker_color(sponsor):
    score = sponsor.get('score', 0)
    if score >= 75:
        return 'green'
    if score >= 50:
        return 'orange'
    return 'red'


================================================================================
FIL: sponsor_match/ui/components/modals.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

"""
Modal dialog components for SponsorMatch application.
"""
import streamlit as st


def show_login_modal():
    """Show a login modal dialog."""
    # Use Streamlit's experimental modal feature if available
    use_experimental = hasattr(st, "modal")

    if use_experimental:
        with st.modal("Logga in", key="login_modal"):
            _render_login_form()
    else:
        # Fallback to expander
        with st.expander("Logga in", expanded=True):
            _render_login_form()


def show_sponsor_modal(sponsor):
    """
    Show a sponsor details modal dialog.

    Args:
        sponsor: Dictionary with sponsor information
    """
    use_experimental = hasattr(st, "modal")
    title = sponsor.get('name', 'Sponsor')

    if use_experimental:
        with st.modal(title, key="sponsor_modal"):
            _render_sponsor_details(sponsor)
    else:
        # Fallback to expander
        with st.expander(title, expanded=True):
            _render_sponsor_details(sponsor)


def show_confirmation_modal(title, message, confirm_text="Bekr√§fta", cancel_text="Avbryt"):
    """
    Show a confirmation dialog and return the result.

    Args:
        title: Modal title
        message: Message to display
        confirm_text: Text for confirm button
        cancel_text: Text for cancel button

    Returns:
        True if confirmed, False otherwise
    """
    use_experimental = hasattr(st, "modal")

    if use_experimental:
        with st.modal(title, key="confirm_modal"):
            st.write(message)
            col1, col2 = st.columns(2)
            with col1:
                if st.button(cancel_text, key="modal_cancel"):
                    return False
            with col2:
                if st.button(confirm_text, key="modal_confirm", type="primary"):
                    return True
    else:
        # Fallback to regular UI
        st.write(message)
        col1, col2 = st.columns(2)
        with col1:
            if st.button(cancel_text, key="confirm_cancel"):
                return False
        with col2:
            if st.button(confirm_text, key="confirm_confirm", type="primary"):
                return True

    return False


def _render_login_form():
    """Render login form content."""
    st.text_input("E-post", key="login_email")
    st.text_input("L√∂senord", type="password", key="login_password")

    col1, col2 = st.columns(2)
    with col1:
        st.checkbox("Kom ih√•g mig", key="remember_me")
    with col2:
        st.markdown(
            "<div style='text-align:right;'><a href='#'>Gl√∂mt l√∂senord?</a></div>",
            unsafe_allow_html=True
        )

    if st.button("Logga in", type="primary", key="do_login"):
        st.success("Inloggning lyckades!")
        return True

    st.markdown("---")
    st.markdown("Har du inget konto? [Registrera dig h√§r](#)")

    return False


def _render_sponsor_details(sponsor):
    """Render sponsor details content."""
    # Extract sponsor details with defaults
    name = sponsor.get('name', 'Unknown Sponsor')
    description = sponsor.get('description', 'No description available.')
    industry = sponsor.get('industry', 'N/A')
    revenue = sponsor.get('revenue_ksek', 'N/A')
    employees = sponsor.get('employees', 'N/A')
    website = sponsor.get('website', '#')
    email = sponsor.get('contact', {}).get('email', 'kontakt@f√∂retag.se')
    phone = sponsor.get('contact', {}).get('phone', 'N/A')

    # Display sponsor information
    st.subheader(name)
    st.write(description)

    # Company details
    st.markdown("### F√∂retagsinformation")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Bransch", industry)
    with col2:
        st.metric("Oms√§ttning", f"{revenue} tkr")
    with col3:
        st.metric("Anst√§llda", employees)

    # Contact information
    st.markdown("### Kontaktuppgifter")
    st.write(f"üìß E-post: {email}")
    st.write(f"üìû Telefon: {phone}")
    if website != '#':
        st.write(f"üåê [Bes√∂k webbplats]({website})")

    # Contact form
    st.markdown("### Skicka meddelande")
    with st.form("contact_form"):
        st.text_area("Meddelande", placeholder="Skriv ditt meddelande h√§r...")
        submitted = st.form_submit_button("Skicka")

        if submitted:
            st.success("Meddelande skickat!")


================================================================================
FIL: sponsor_match/ui/components/pagination.py
================================================================================

"""
sponsor_match/ui/components/pagination.py

Efficient pagination component for handling 82,776 companies
"""
import streamlit as st
import pandas as pd
from typing import Optional


def paginate_dataframe(
        df: pd.DataFrame,
        page_size: int = 50,
        key_prefix: str = "page"
) -> pd.DataFrame:
    """
    Implement efficient pagination with session state.
    Handles large datasets without performance degradation.

    Args:
        df: DataFrame to paginate
        page_size: Number of items per page
        key_prefix: Prefix for session state keys (for multiple paginators)

    Returns:
        Paginated slice of the DataFrame
    """
    # Initialise page in session state
    page_key = f'{key_prefix}_number'
    if page_key not in st.session_state:
        st.session_state[page_key] = 1

    # Calculate total pages
    total_rows = len(df)
    total_pages = (total_rows // page_size) + (1 if total_rows % page_size else 0)

    # Ensure page is within valid range
    if st.session_state[page_key] > total_pages:
        st.session_state[page_key] = total_pages
    elif st.session_state[page_key] < 1:
        st.session_state[page_key] = 1

    # Calculate indices
    start_idx = (st.session_state[page_key] - 1) * page_size
    end_idx = min(start_idx + page_size, total_rows)

    # Pagination controls in columns
    col1, col2, col3, col4, col5 = st.columns([1, 1, 2, 1, 1])

    with col1:
        if st.button("‚èÆÔ∏è First",
                     disabled=(st.session_state[page_key] == 1),
                     key=f"{key_prefix}_first"):
            st.session_state[page_key] = 1
            st.rerun()

    with col2:
        if st.button("‚óÄÔ∏è Prev",
                     disabled=(st.session_state[page_key] == 1),
                     key=f"{key_prefix}_prev"):
            st.session_state[page_key] -= 1
            st.rerun()

    with col3:
        # Direct page input with better formatting
        new_page = st.number_input(
            f"Page {st.session_state[page_key]} of {total_pages}",
            min_value=1,
            max_value=total_pages,
            value=st.session_state[page_key],
            key=f"{key_prefix}_input",
            label_visibility="visible"
        )
        if new_page != st.session_state[page_key]:
            st.session_state[page_key] = new_page
            st.rerun()

    with col4:
        if st.button("Next ‚ñ∂Ô∏è",
                     disabled=(st.session_state[page_key] == total_pages),
                     key=f"{key_prefix}_next"):
            st.session_state[page_key] += 1
            st.rerun()

    with col5:
        if st.button("Last ‚è≠Ô∏è",
                     disabled=(st.session_state[page_key] == total_pages),
                     key=f"{key_prefix}_last"):
            st.session_state[page_key] = total_pages
            st.rerun()

    # Show row information
    st.caption(f"Showing {start_idx + 1}-{end_idx} of {total_rows} items")

    # Return paginated slice
    return df.iloc[start_idx:end_idx]


def paginate_results(
        results: list,
        page_size: int = 20,
        key_prefix: str = "results"
) -> list:
    """
    Paginate a list of results (for non-DataFrame data).

    Args:
        results: List to paginate
        page_size: Number of items per page
        key_prefix: Prefix for session state keys

    Returns:
        Paginated slice of the list
    """
    # Convert to DataFrame for reuse of pagination logic
    df = pd.DataFrame(results)
    paginated_df = paginate_dataframe(df, page_size, key_prefix)

    # Convert back to list of dictionaries
    return paginated_df.to_dict('records')


def get_page_info(
        total_items: int,
        page_size: int = 50,
        key_prefix: str = "page"
) -> dict:
    """
    Get current pagination information.

    Returns:
        Dictionary with page info (current_page, total_pages, start_idx, end_idx)
    """
    page_key = f'{key_prefix}_number'
    if page_key not in st.session_state:
        st.session_state[page_key] = 1

    total_pages = (total_items // page_size) + (1 if total_items % page_size else 0)
    current_page = st.session_state[page_key]
    start_idx = (current_page - 1) * page_size
    end_idx = min(start_idx + page_size, total_items)

    return {
        'current_page': current_page,
        'total_pages': total_pages,
        'start_idx': start_idx,
        'end_idx': end_idx,
        'page_size': page_size,
        'total_items': total_items
    }


# AgGrid pagination for advanced features
def create_aggrid_config(page_size: int = 50):
    """
    Create AgGrid configuration with pagination.

    Returns:
        Dictionary with AgGrid options
    """
    return {
        'pagination': True,
        'paginationPageSize': page_size,
        'paginationAutoPageSize': False,
        'defaultColDef': {
            'filter': True,
            'sortable': True,
            'resizable': True
        },
        'enableRangeSelection': True,
        'suppressMenuHide': True,
        'animateRows': True,
        'rowSelection': 'single'
    }

================================================================================
FIL: sponsor_match/ui/components/sidebar.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

"""
Sidebar component for SponsorMatch application.
"""
import streamlit as st

from sponsor_match.ui.utils.sessions import clear_session_data


def render_sidebar():
    """Render the application sidebar."""
    with st.sidebar:
        st.title("üèÜ SponsorMatch AI")
        st.markdown("Hitta r√§tt sponsorer f√∂r din idrottsf√∂rening")
        st.divider()

        # Settings section
        st.subheader("Inst√§llningar")
        api_key = st.text_input("API-nyckel", value="demo-key", type="password")
        st.checkbox("Avancerad matchning", value=True,
                    help="Aktivera AI-baserad matchning")

        # Language selection
        st.selectbox("Spr√•k", ["Svenska", "English"], index=0)

        st.divider()

        # User actions
        if st.button("Rensa s√∂khistorik"):
            clear_session_data("search_results")
            clear_session_data("search_scores")
            st.success("S√∂khistorik rensad!")

        if st.button("Logga ut"):
            clear_session_data()
            st.success("Du har loggats ut.")

        # About section
        st.markdown("### Om SponsorMatch AI")
        st.markdown("""
        SponsorMatch AI hj√§lper idrottsf√∂reningar att hitta och kontakta l√§mpliga 
        f√∂retag som kan bli sponsorer.

        Vi anv√§nder AI f√∂r att matcha f√∂reningar med f√∂retag baserat p√• geografi, 
        storlek, bransch och v√§rderingar.
        """)

        st.markdown("Made with ‚ù§Ô∏è by Team 14")

        # Version info
        st.caption("Version 1.0.0")


================================================================================
FIL: sponsor_match/ui/components/visualizations.py
================================================================================

"""
sponsor_match/ui/components/visualizations.py

High-performance visualizations using Altair.
Replaces slower Plotly charts for better performance with 82,776 companies.
"""
import altair as alt
import pandas as pd
import streamlit as st
from typing import Optional, Dict, List


def create_scatter_plot(
    df: pd.DataFrame,
    x_col: str = 'revenue',
    y_col: str = 'employees',
    color_col: str = 'industry',
    size_col: Optional[str] = None,
    title: str = 'Company Performance Matrix'
) -> alt.Chart:
    """
    Create fast, interactive scatter plot with Altair.
    Handles large datasets efficiently.

    Args:
        df: DataFrame with company data
        x_col: Column for x-axis
        y_col: Column for y-axis
        color_col: Column for color encoding
        size_col: Optional column for size encoding
        title: Chart title

    Returns:
        Altair chart object
    """
    # Sample data if too large for performance
    if len(df) > 5000:
        df_sample = df.sample(n=5000, random_state=42)
        title += " (Sample)"
    else:
        df_sample = df

    # Base chart
    base = alt.Chart(df_sample).mark_circle(size=60)

    # Encodings
    encodings = {
        'x': alt.X(f'{x_col}:Q', title=x_col.replace('_', ' ').title()),
        'y': alt.Y(f'{y_col}:Q', title=y_col.replace('_', ' ').title()),
        'color': alt.Color(f'{color_col}:N', legend=alt.Legend(title=color_col.title())),
        'tooltip': [
            alt.Tooltip('name:N', title='Company'),
            alt.Tooltip(f'{x_col}:Q', title=x_col.title(), format=',.0f'),
            alt.Tooltip(f'{y_col}:Q', title=y_col.title(), format=',.0f'),
            alt.Tooltip(f'{color_col}:N', title=color_col.title())
        ]
    }

    # Add size encoding if specified
    if size_col:
        encodings['size'] = alt.Size(f'{size_col}:Q', scale=alt.Scale(range=[50, 500]))
        encodings['tooltip'].append(alt.Tooltip(f'{size_col}:Q', title=size_col.title()))

    # Create chart
    chart = base.encode(**encodings).interactive().properties(
        width=700,
        height=400,
        title=title
    )

    return chart


def create_bar_chart(
    df: pd.DataFrame,
    category_col: str = 'size_bucket',
    title: str = 'Company Size Distribution'
) -> alt.Chart:
    """
    Create responsive bar chart for categorical data.

    Args:
        df: DataFrame with company data
        category_col: Column for categories
        title: Chart title

    Returns:
        Altair chart object
    """
    # Count by category
    count_df = df[category_col].value_counts().reset_index()
    count_df.columns = [category_col, 'count']

    # Order categories
    if category_col == 'size_bucket':
        order = ['small', 'medium', 'large', 'enterprise']
        count_df['order'] = count_df[category_col].map({v: i for i, v in enumerate(order)})
        count_df = count_df.sort_values('order')

    # Create chart
    chart = alt.Chart(count_df).mark_bar().encode(
        x=alt.X(f'{category_col}:N',
                title=category_col.replace('_', ' ').title(),
                sort=order if category_col == 'size_bucket' else None),
        y=alt.Y('count:Q', title='Number of Companies'),
        color=alt.Color(f'{category_col}:N',
                       scale=alt.Scale(scheme='blues'),
                       legend=None),
        tooltip=[
            alt.Tooltip(f'{category_col}:N', title='Category'),
            alt.Tooltip('count:Q', title='Count', format=',')
        ]
    ).properties(
        width=400,
        height=300,
        title=title
    )

    return chart


def create_heatmap(
    df: pd.DataFrame,
    lat_col: str = 'latitude',
    lon_col: str = 'longitude',
    value_col: str = 'score',
    title: str = 'Geographic Distribution Heatmap'
) -> alt.Chart:
    """
    Create geographic heatmap using hexbins for performance.

    Args:
        df: DataFrame with location data
        lat_col: Column for latitude
        lon_col: Column for longitude
        value_col: Column for values (e.g., score)
        title: Chart title

    Returns:
        Altair chart object
    """
    # Sample if too large
    if len(df) > 10000:
        df_sample = df.sample(n=10000, random_state=42)
    else:
        df_sample = df

    # Create hexbin chart
    chart = alt.Chart(df_sample).mark_circle(size=10, opacity=0.6).encode(
        x=alt.X(f'{lon_col}:Q',
                title='Longitude',
                scale=alt.Scale(domain=[df[lon_col].min(), df[lon_col].max()])),
        y=alt.Y(f'{lat_col}:Q',
                title='Latitude',
                scale=alt.Scale(domain=[df[lat_col].min(), df[lat_col].max()])),
        color=alt.Color(f'mean({value_col}):Q',
                       scale=alt.Scale(scheme='viridis'),
                       title=f'Avg {value_col.title()}'),
        size=alt.Size('count():Q',
                     scale=alt.Scale(range=[10, 200]),
                     legend=None),
        tooltip=[
            alt.Tooltip('count():Q', title='Companies'),
            alt.Tooltip(f'mean({value_col}):Q', title=f'Avg {value_col}', format='.2f')
        ]
    ).properties(
        width=600,
        height=600,
        title=title
    )

    return chart


def create_distribution_chart(
    df: pd.DataFrame,
    value_col: str,
    title: str,
    bins: int = 30
) -> alt.Chart:
    """
    Create histogram for value distributions.

    Args:
        df: DataFrame with data
        value_col: Column to plot distribution
        title: Chart title
        bins: Number of bins

    Returns:
        Altair chart object
    """
    chart = alt.Chart(df).mark_bar().encode(
        x=alt.X(f'{value_col}:Q',
                bin=alt.Bin(maxbins=bins),
                title=value_col.replace('_', ' ').title()),
        y=alt.Y('count()',
                title='Frequency'),
        color=alt.value('#2563eb'),
        tooltip=[
            alt.Tooltip(f'{value_col}:Q', title=value_col.title(), bin=True),
            alt.Tooltip('count()', title='Count')
        ]
    ).properties(
        width=500,
        height=300,
        title=title
    )

    return chart


def create_time_series(
    df: pd.DataFrame,
    date_col: str,
    value_col: str,
    group_col: Optional[str] = None,
    title: str = 'Time Series'
) -> alt.Chart:
    """
    Create time series line chart.

    Args:
        df: DataFrame with time series data
        date_col: Date column
        value_col: Value column
        group_col: Optional grouping column
        title: Chart title

    Returns:
        Altair chart object
    """
    base = alt.Chart(df).mark_line(point=True)

    encodings = {
        'x': alt.X(f'{date_col}:T', title='Date'),
        'y': alt.Y(f'{value_col}:Q', title=value_col.replace('_', ' ').title()),
        'tooltip': [
            alt.Tooltip(f'{date_col}:T', title='Date'),
            alt.Tooltip(f'{value_col}:Q', title=value_col.title(), format=',.0f')
        ]
    }

    if group_col:
        encodings['color'] = alt.Color(f'{group_col}:N', title=group_col.title())
        encodings['tooltip'].append(alt.Tooltip(f'{group_col}:N', title=group_col.title()))

    chart = base.encode(**encodings).properties(
        width=700,
        height=300,
        title=title
    )

    return chart


def create_correlation_matrix(
    df: pd.DataFrame,
    numeric_cols: List[str],
    title: str = 'Feature Correlation Matrix'
) -> alt.Chart:
    """
    Create correlation matrix heatmap.

    Args:
        df: DataFrame with numeric data
        numeric_cols: List of numeric columns to correlate
        title: Chart title

    Returns:
        Altair chart object
    """
    # Calculate correlations
    corr_df = df[numeric_cols].corr()

    # Reshape for Altair
    corr_data = []
    for i, col1 in enumerate(numeric_cols):
        for j, col2 in enumerate(numeric_cols):
            corr_data.append({
                'var1': col1,
                'var2': col2,
                'correlation': corr_df.iloc[i, j]
            })

    corr_data_df = pd.DataFrame(corr_data)

    # Create heatmap
    chart = alt.Chart(corr_data_df).mark_rect().encode(
        x=alt.X('var1:N', title=''),
        y=alt.Y('var2:N', title=''),
        color=alt.Color('correlation:Q',
                       scale=alt.Scale(scheme='redblue', domain=[-1, 1]),
                       title='Correlation'),
        tooltip=[
            alt.Tooltip('var1:N', title='Variable 1'),
            alt.Tooltip('var2:N', title='Variable 2'),
            alt.Tooltip('correlation:Q', title='Correlation', format='.3f')
        ]
    ).properties(
        width=500,
        height=500,
        title=title
    )

    return chart


# Composite visualization functions
def create_analytics_dashboard(
    df: pd.DataFrame,
    title: str = "Analytics Dashboard"
) -> Dict[str, alt.Chart]:
    """
    Create a complete analytics dashboard with multiple charts.

    Args:
        df: DataFrame with company/sponsor data
        title: Dashboard title

    Returns:
        Dictionary of chart objects
    """
    charts = {}

    # Size distribution
    charts['size_dist'] = create_bar_chart(
        df,
        category_col='size_bucket',
        title='Company Size Distribution'
    )

    # Score distribution (if available)
    if 'score' in df.columns:
        charts['score_dist'] = create_distribution_chart(
            df,
            value_col='score',
            title='Match Score Distribution'
        )

    # Geographic scatter (if coordinates available)
    if 'latitude' in df.columns and 'longitude' in df.columns:
        charts['geo_scatter'] = alt.Chart(df.sample(n=min(1000, len(df)))).mark_circle(size=30).encode(
            x=alt.X('longitude:Q', scale=alt.Scale(domain=[11.8, 12.1])),
            y=alt.Y('latitude:Q', scale=alt.Scale(domain=[57.6, 57.8])),
            color=alt.Color('size_bucket:N'),
            tooltip=['name:N', 'size_bucket:N']
        ).properties(
            width=400,
            height=400,
            title='Geographic Distribution (Sample)'
        )

    return charts


================================================================================
FIL: sponsor_match/ui/utils/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/ui/utils/archive_migration.py
================================================================================

#!/usr/bin/env python3
"""
utils/archive_migration.py

Complete script for identifying and archiving obsolete files from the SponsorMatch AI project.
This script safely moves outdated files to the archive folder while maintaining a detailed
audit trail and allowing for rollback if needed.
"""

import argparse
import hashlib
import json
import logging
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Project root detection
PROJECT_ROOT = Path(__file__).resolve().parents[1]
ARCHIVE_ROOT = PROJECT_ROOT / "archive"

# Archive configuration
ARCHIVE_CONFIG = {
    "version": "2.0",
    "date_format": "%Y%m%d_%H%M%S",
    "manifest_filename": "archive_manifest.json",
    "rollback_filename": "rollback_manifest.json",
    "dry_run_by_default": True
}


class FileArchiver:
    """
    Manages the archiving of obsolete project files with safety checks and rollback capability.
    """

    def __init__(self, dry_run: bool = True):
        """
        Initialize the archiver.

        Args:
            dry_run: If True, only simulate the archiving without moving files
        """
        self.dry_run = dry_run
        self.timestamp = datetime.now().strftime(ARCHIVE_CONFIG["date_format"])
        self.archive_dir = ARCHIVE_ROOT / f"archive_{self.timestamp}"
        self.manifest_path = self.archive_dir / ARCHIVE_CONFIG["manifest_filename"]
        self.rollback_path = self.archive_dir / ARCHIVE_CONFIG["rollback_filename"]

        # Track operations
        self.operations = []
        self.errors = []

    def get_file_hash(self, filepath: Path) -> str:
        """Calculate SHA256 hash of a file for integrity verification."""
        sha256_hash = hashlib.sha256()
        with open(filepath, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()

    def identify_obsolete_files(self) -> List[Dict[str, any]]:
        """
        Identify files that should be archived based on various criteria.

        Returns:
            List of dictionaries containing file information and archiving reason
        """
        obsolete_files = []

        # Pattern-based identification
        patterns_to_archive = [
            # Old data ingestion scripts (replaced by geocoded CSV pipeline)
            {
                "pattern": "**/ingest_*.py",
                "exclude": ["ingest_associations_fixed.py", "ingest_companies.py"],  # Keep these
                "reason": "Replaced by geocoded CSV pipeline"
            },
            {
                "pattern": "**/manual_geocoding*.py",
                "reason": "Geocoding now handled by pre-processed CSVs"
            },
            {
                "pattern": "**/*_old.py",
                "reason": "Explicitly marked as old"
            },
            {
                "pattern": "**/*_backup.py",
                "reason": "Backup file"
            },
            {
                "pattern": "**/*_test.py",
                "exclude": ["test_*.py"],  # Keep proper test files
                "reason": "Temporary test file"
            },
            {
                "pattern": "**/*_v1.py",
                "reason": "Version 1 file superseded"
            },
            {
                "pattern": "**/temp_*.py",
                "reason": "Temporary file"
            },
            {
                "pattern": "**/examine.py",
                "reason": "Ad-hoc examination script"
            }
        ]

        # Check each pattern
        for pattern_config in patterns_to_archive:
            pattern = pattern_config["pattern"]
            exclude = pattern_config.get("exclude", [])
            reason = pattern_config["reason"]

            for filepath in PROJECT_ROOT.glob(pattern):
                # Skip if already in archive
                if "archive" in filepath.parts:
                    continue

                # Skip if in exclude list
                if any(exc in filepath.name for exc in exclude):
                    continue

                # Skip __pycache__ directories
                if "__pycache__" in filepath.parts:
                    continue

                obsolete_files.append({
                    "path": filepath,
                    "relative_path": filepath.relative_to(PROJECT_ROOT),
                    "reason": reason,
                    "size": filepath.stat().st_size,
                    "modified": datetime.fromtimestamp(filepath.stat().st_mtime).isoformat(),
                    "hash": self.get_file_hash(filepath) if filepath.is_file() else None
                })

        # Content-based identification
        obsolete_files.extend(self._identify_by_content())

        # Deduplicate
        seen = set()
        unique_files = []
        for file_info in obsolete_files:
            path_str = str(file_info["path"])
            if path_str not in seen:
                seen.add(path_str)
                unique_files.append(file_info)

        return unique_files

    def _identify_by_content(self) -> List[Dict[str, any]]:
        """
        Identify obsolete files by examining their content.

        Looks for deprecated imports, hardcoded paths, and other indicators.
        """
        content_based_obsolete = []

        # Patterns that indicate obsolescence
        obsolete_indicators = [
            ("from sklearn.cross_validation import", "Uses deprecated sklearn API"),
            ("import MySQLdb", "Uses deprecated MySQL driver"),
            ("/old_data/", "References old data directory"),
            ("/home/user/old_project/", "Contains hardcoded old project paths"),
            ("# DEPRECATED", "Marked as deprecated in comments"),
            ("# TODO: Remove this file", "Marked for removal in comments")
        ]

        # Check Python files
        for py_file in PROJECT_ROOT.glob("**/*.py"):
            # Skip if already in archive or __pycache__
            if "archive" in py_file.parts or "__pycache__" in py_file.parts:
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                for pattern, reason in obsolete_indicators:
                    if pattern in content:
                        content_based_obsolete.append({
                            "path": py_file,
                            "relative_path": py_file.relative_to(PROJECT_ROOT),
                            "reason": reason,
                            "size": py_file.stat().st_size,
                            "modified": datetime.fromtimestamp(py_file.stat().st_mtime).isoformat(),
                            "hash": self.get_file_hash(py_file)
                        })
                        break  # One reason is enough

            except Exception as e:
                logger.warning(f"Could not examine {py_file}: {e}")

        return content_based_obsolete

    def create_archive_structure(self):
        """Create the archive directory structure."""
        if not self.dry_run:
            self.archive_dir.mkdir(parents=True, exist_ok=True)

            # Create subdirectories to maintain organization
            subdirs = ["data", "models", "scripts", "ui", "misc"]
            for subdir in subdirs:
                (self.archive_dir / subdir).mkdir(exist_ok=True)

    def categorize_file(self, relative_path: Path) -> str:
        """Determine which archive subdirectory a file belongs to."""
        path_str = str(relative_path).lower()

        if "data" in path_str or "ingest" in path_str or "csv" in path_str:
            return "data"
        elif "model" in path_str or "clustering" in path_str or "ml" in path_str:
            return "models"
        elif "ui" in path_str or "page" in path_str or "app" in path_str:
            return "ui"
        elif any(script in path_str for script in ["train", "test", "check", "build"]):
            return "scripts"
        else:
            return "misc"

    def archive_file(self, file_info: Dict[str, any]) -> Optional[Dict[str, any]]:
        """
        Archive a single file.

        Args:
            file_info: Dictionary with file information

        Returns:
            Operation record or None if failed
        """
        source_path = file_info["path"]
        relative_path = file_info["relative_path"]

        # Determine archive location
        category = self.categorize_file(relative_path)
        archive_path = self.archive_dir / category / relative_path.name

        # Ensure unique filename if collision
        if archive_path.exists():
            stem = archive_path.stem
            suffix = archive_path.suffix
            counter = 1
            while archive_path.exists():
                archive_path = archive_path.parent / f"{stem}_{counter}{suffix}"
                counter += 1

        operation = {
            "timestamp": datetime.now().isoformat(),
            "source": str(source_path),
            "destination": str(archive_path),
            "relative_path": str(relative_path),
            "category": category,
            "reason": file_info["reason"],
            "file_size": file_info["size"],
            "file_hash": file_info["hash"],
            "dry_run": self.dry_run
        }

        try:
            if not self.dry_run:
                # Create parent directory
                archive_path.parent.mkdir(parents=True, exist_ok=True)

                # Move the file
                shutil.move(str(source_path), str(archive_path))

                # Verify the move
                if archive_path.exists() and not source_path.exists():
                    # Verify integrity
                    if file_info["hash"] and self.get_file_hash(archive_path) == file_info["hash"]:
                        operation["status"] = "success"
                        operation["verified"] = True
                    else:
                        operation["status"] = "success_unverified"
                        operation["verified"] = False
                else:
                    operation["status"] = "failed"
                    operation["error"] = "File not properly moved"
            else:
                operation["status"] = "simulated"

            self.operations.append(operation)
            return operation

        except Exception as e:
            operation["status"] = "error"
            operation["error"] = str(e)
            self.errors.append(operation)
            logger.error(f"Failed to archive {source_path}: {e}")
            return None

    def generate_manifest(self) -> Dict[str, any]:
        """Generate a comprehensive manifest of the archiving operation."""
        manifest = {
            "version": ARCHIVE_CONFIG["version"],
            "timestamp": self.timestamp,
            "dry_run": self.dry_run,
            "summary": {
                "total_files": len(self.operations),
                "successful": len([op for op in self.operations if op.get("status") == "success"]),
                "failed": len([op for op in self.operations if op.get("status") == "failed"]),
                "errors": len(self.errors),
                "total_size": sum(op.get("file_size", 0) for op in self.operations)
            },
            "operations": self.operations,
            "errors": self.errors,
            "categories": {}
        }

        # Group by category
        for op in self.operations:
            category = op.get("category", "misc")
            if category not in manifest["categories"]:
                manifest["categories"][category] = []
            manifest["categories"][category].append(op["relative_path"])

        return manifest

    def save_manifest(self, manifest: Dict[str, any]):
        """Save the manifest to disk."""
        if not self.dry_run:
            self.manifest_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.manifest_path, 'w') as f:
                json.dump(manifest, f, indent=2)
            logger.info(f"Manifest saved to {self.manifest_path}")

    def generate_rollback_script(self):
        """Generate a script to reverse the archiving operation."""
        rollback_script = f"""#!/usr/bin/env python3
# Auto-generated rollback script for archive_{self.timestamp}
# Generated on {datetime.now().isoformat()}

import shutil
import json
from pathlib import Path

def rollback():
    manifest_path = Path("{self.manifest_path}")

    with open(manifest_path, 'r') as f:
        manifest = json.load(f)

    successful_rollbacks = 0
    failed_rollbacks = 0

    for operation in manifest["operations"]:
        if operation["status"] == "success":
            source = Path(operation["destination"])
            destination = Path(operation["source"])

            try:
                if source.exists():
                    destination.parent.mkdir(parents=True, exist_ok=True)
                    shutil.move(str(source), str(destination))
                    print(f"Restored: {{destination}}")
                    successful_rollbacks += 1
                else:
                    print(f"Warning: {{source}} not found")
            except Exception as e:
                print(f"Failed to restore {{destination}}: {{e}}")
                failed_rollbacks += 1

    print(f"\\nRollback complete: {{successful_rollbacks}} restored, {{failed_rollbacks}} failed")

if __name__ == "__main__":
    rollback()
"""

        if not self.dry_run:
            with open(self.rollback_path, 'w') as f:
                f.write(rollback_script)

            # Make executable
            os.chmod(self.rollback_path, 0o755)
            logger.info(f"Rollback script saved to {self.rollback_path}")

    def print_summary(self, obsolete_files: List[Dict[str, any]]):
        """Print a summary of files to be archived."""
        print("\n" + "=" * 60)
        print("ARCHIVE MIGRATION SUMMARY")
        print("=" * 60)

        # Group by reason
        by_reason = {}
        for file_info in obsolete_files:
            reason = file_info["reason"]
            if reason not in by_reason:
                by_reason[reason] = []
            by_reason[reason].append(file_info)

        # Print each group
        for reason, files in by_reason.items():
            print(f"\n{reason}:")
            print("-" * len(reason))

            for file_info in sorted(files, key=lambda x: x["relative_path"]):
                size_kb = file_info["size"] / 1024
                print(f"  ‚Ä¢ {file_info['relative_path']} ({size_kb:.1f} KB)")

        # Total statistics
        total_size = sum(f["size"] for f in obsolete_files)
        print(f"\nTotal files to archive: {len(obsolete_files)}")
        print(f"Total size: {total_size / 1024 / 1024:.2f} MB")

        if self.dry_run:
            print("\n‚ö†Ô∏è  DRY RUN MODE - No files will be moved")
        else:
            print("\n‚ö†Ô∏è  FILES WILL BE MOVED - Make sure you have backups!")

        print("=" * 60 + "\n")

    def run(self) -> bool:
        """
        Execute the archiving process.

        Returns:
            True if successful, False otherwise
        """
        logger.info(f"Starting archive migration (dry_run={self.dry_run})")

        # Identify obsolete files
        obsolete_files = self.identify_obsolete_files()

        if not obsolete_files:
            logger.info("No obsolete files found")
            return True

        # Print summary
        self.print_summary(obsolete_files)

        # Ask for confirmation if not dry run
        if not self.dry_run:
            response = input("\nProceed with archiving? (yes/no): ")
            if response.lower() != "yes":
                logger.info("Archiving cancelled by user")
                return False

        # Create archive structure
        self.create_archive_structure()

        # Archive each file
        logger.info(f"Archiving {len(obsolete_files)} files...")

        for i, file_info in enumerate(obsolete_files, 1):
            logger.info(f"[{i}/{len(obsolete_files)}] Archiving {file_info['relative_path']}")
            self.archive_file(file_info)

        # Generate and save manifest
        manifest = self.generate_manifest()
        self.save_manifest(manifest)

        # Generate rollback script
        self.generate_rollback_script()

        # Print final summary
        print("\n" + "=" * 60)
        print("ARCHIVE MIGRATION COMPLETE")
        print("=" * 60)

        if self.dry_run:
            print("\nDRY RUN SUMMARY:")
            print(f"  ‚Ä¢ Would archive {len(self.operations)} files")
            print(f"  ‚Ä¢ Total size: {manifest['summary']['total_size'] / 1024 / 1024:.2f} MB")
            print(f"  ‚Ä¢ Archive location: {self.archive_dir}")
        else:
            print(f"\nSUMMARY:")
            print(f"  ‚Ä¢ Archived {manifest['summary']['successful']} files successfully")
            print(f"  ‚Ä¢ Failed: {manifest['summary']['failed']}")
            print(f"  ‚Ä¢ Errors: {manifest['summary']['errors']}")
            print(f"  ‚Ä¢ Archive location: {self.archive_dir}")
            print(f"  ‚Ä¢ Manifest: {self.manifest_path}")
            print(f"  ‚Ä¢ Rollback script: {self.rollback_path}")

        return len(self.errors) == 0


def main():
    """Main entry point for the archive migration script."""
    parser = argparse.ArgumentParser(
        description="Archive obsolete files from the SponsorMatch AI project"
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="Actually move files (default is dry-run)"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging"
    )

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Create archiver instance
    archiver = FileArchiver(dry_run=not args.execute)

    # Run the archiving process
    success = archiver.run()

    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    import sys

    main()


================================================================================
FIL: sponsor_match/ui/utils/sessions.py
================================================================================

"""
Utilities for managing Streamlit session state.
"""
import streamlit as st


def get_session_data(key, default=None):
    """
    Get data from session state with fallback to default.

    Args:
        key: Session state key
        default: Default value if key doesn't exist

    Returns:
        Value from session state or default
    """
    return st.session_state.get(key, default)


def set_session_data(key, value):
    """
    Set data in session state.

    Args:
        key: Session state key
        value: Value to store
    """
    st.session_state[key] = value


def clear_session_data(key=None):
    """
    Clear data from session state.

    Args:
        key: Specific key to clear, or None to clear all app-specific keys
    """
    if key is not None and key in st.session_state:
        del st.session_state[key]
    elif key is None:
        # Clear all app-specific keys (doesn't affect Streamlit's internal keys)
        app_keys = [k for k in st.session_state.keys()
                    if not k.startswith('_') and k not in ['formSubmitter', 'formKey']]
        for k in app_keys:
            del st.session_state[k]


================================================================================
FIL: sponsor_match/ui/pages/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/ui/pages/home.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

#!/usr/bin/env python3
"""
sponsor_match/ui/pages/home.py

Home page for SponsorMatch application.
"""

import streamlit as st

def render_home_page():
    """Render the home page with responsive cards."""
    st.markdown(
        "<h2 style='font-size:2rem;font-weight:600;color:var(--primaryColor);'>"
        "V√§lkommen till SponsorMatch</h2>",
        unsafe_allow_html=True,
    )

    # open the flex container
    st.markdown('<div class="card-container">', unsafe_allow_html=True)

    # each card
    cards = [
        ("‚ú®", "Tips & tricks", "R√•d f√∂r att locka sponsorer snabbare."),
        ("‚öôÔ∏è", "Inst√§llningar",       "Justera profil, sekretess och synlighet."),
        ("‚ÑπÔ∏è", "Om SponsorMatch",     "S√• fungerar plattformen och aff√§rsmodellen."),
    ]
    for icon, title, desc in cards:
        st.markdown(
            f"""
            <div class="card">
              <div style="font-size:2rem;color:var(--primaryColor);">{icon}</div>
              <h3 style="margin:0.5rem 0;color:var(--primaryColor);">{title}</h3>
              <p style="margin:0;color:var(--textColor);">{desc}</p>
            </div>
            """,
            unsafe_allow_html=True,
        )

    # close the flex container
    st.markdown('</div>', unsafe_allow_html=True)


================================================================================
FIL: sponsor_match/ui/pages/profile.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

#!/usr/bin/env python3
"""
sponsor_match/ui/pages/profile.py

Streamlit page for managing club profile.
"""

import streamlit as st

# fix: it's session.py, not sessions.py
from sponsor_match.ui.utils.sessions import get_session_data, set_session_data


def render_profile_page():
    st.markdown(
        "<h2 style='font-size:2rem;font-weight:600;color:var(--primaryColor);'>"
        "Min f√∂rening</h2>",
        unsafe_allow_html=True,
    )

    # get_session_data() may return None, so we coalesce to a dict
    club = get_session_data("selected_club") or {}

    if club:
        _render_profile_form(club)
    else:
        st.info(
            "Du har inte valt n√•gon f√∂rening. "
            "Anv√§nd s√∂kfunktionen f√∂r att hitta din f√∂rening."
        )
        _render_profile_form(None)

    with st.expander("Sponsorhistorik", expanded=False):
        _render_sponsorship_history()

    with st.expander("Inst√§llningar", expanded=False):
        _render_preferences()


def _render_profile_form(club: dict | None = None):
    with st.form("profile_form"):
        # prefill from club dict or fall back to empty strings
        name    = st.text_input("F√∂reningens namn", value=club.get("name","") if club else "")
        address = st.text_input("Adress",           value=club.get("address","") if club else "")

        # size bucket select
        size_labels = ["Liten", "Medel", "Stor"]
        rev_map     = {"Liten":"small","Medel":"medium","Stor":"large"}
        # figure out which index to preselect
        if club and club.get("size_bucket") in {"small","medium","large"}:
            pre = {"small":"Liten","medium":"Medel","large":"Stor"}[club["size_bucket"]]
            default_idx = size_labels.index(pre)
        else:
            default_idx = 1  # Medel
        size_sel = st.selectbox("Storlek", size_labels, index=default_idx)

        email = st.text_input("E-post",   value=club.get("email","") if club else "")
        phone = st.text_input("Telefon",  value=club.get("phone","") if club else "")
        desc  = st.text_area("Beskrivning", value=club.get("description","") if club else "")

        if st.form_submit_button("Spara profil"):
            st.success("Profilen har sparats!")
            profile = {
                "name":         name,
                "address":      address,
                "size_bucket":  rev_map[size_sel],
                "email":        email,
                "phone":        phone,
                "description":  desc,
            }
            # preserve id + coords if they existed
            if club:
                for key in ("id","latitude","longitude"):
                    if key in club:
                        profile[key] = club[key]
            set_session_data("selected_club", profile)


def _render_sponsorship_history():
    st.markdown("#### Nuvarande sponsorer")
    history = st.session_state.get("sponsors_history", [])
    if history:
        for s in history:
            st.write(f"**{s['name']}** ({s['contract_date']} ‚Äì {s['end_date']}) ‚Ä¢ {s['status']}")
            st.write("---")
    else:
        st.write("Inga aktiva sponsoravtal.")


def _render_preferences():
    st.markdown("#### Notifikationsinst√§llningar")
    st.checkbox("E-postaviseringar",   value=True,  key="email_notifications")
    st.checkbox("SMS-aviseringar",      value=False, key="sms_notifications")

    st.markdown("#### Sekretess")
    st.checkbox("Visa f√∂rening publikt",      value=True,  key="public_profile")
    st.checkbox("Till√•t kontakt fr√•n f√∂retag", value=True,  key="allow_contact")

    if st.button("Spara inst√§llningar", key="save_prefs"):
        st.success("Inst√§llningarna har sparats!")


================================================================================
FIL: sponsor_match/ui/pages/search.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

#!/usr/bin/env python3
"""
sponsor_match/ui/pages/search.py

Complete search page implementation with proper score display, map integration,
and comprehensive error handling. This fixes the 108% display issue.
"""

import logging
from typing import List, Dict, Optional, Tuple

import folium
import numpy as np
import pandas as pd
import streamlit as st
from folium.plugins import MarkerCluster, HeatMap
from streamlit_folium import st_folium

from sponsor_match.core.db import get_engine
from sponsor_match.ml.pipeline import score_and_rank
from sponsor_match.services.service import SponsorMatchService

# Configure logging
logger = logging.getLogger(__name__)

# Constants for UI
DEFAULT_MAX_DISTANCE = 25  # km
DEFAULT_TOP_N = 10
MAP_HEIGHT = 500
SCORE_THRESHOLD = 0.3  # Minimum score to display

# Color scheme for match quality
MATCH_COLORS = {
    'excellent': '#10b981',  # Green
    'good': '#3b82f6',  # Blue
    'fair': '#f59e0b',  # Orange
    'possible': '#6b7280'  # Gray
}


def validate_score(score: float, entity_name: str = "") -> float:
    """
    Validate and clamp score to [0, 1] range.

    This function ensures that all scores displayed in the UI are valid percentages.
    It logs warnings when invalid scores are detected for debugging purposes.
    """
    if not isinstance(score, (int, float)):
        logger.error(f"Invalid score type {type(score)} for {entity_name}")
        return 0.0

    if np.isnan(score) or np.isinf(score):
        logger.error(f"NaN or Inf score for {entity_name}")
        return 0.0

    if score < 0 or score > 1:
        logger.warning(f"Score {score} out of range for {entity_name}, clamping")
        return np.clip(score, 0.0, 1.0)

    return float(score)


def format_percentage(score: float) -> str:
    """
    Format score as percentage with validation.

    This function ensures that percentage displays never exceed 100%.
    """
    validated_score = validate_score(score)
    percentage = validated_score * 100

    # Extra safety check
    if percentage > 100:
        logger.error(f"Percentage {percentage}% exceeds 100% after validation!")
        percentage = 100.0

    return f"{percentage:.1f}%"


def get_match_quality(score: float) -> Tuple[str, str]:
    """
    Get match quality label and color based on score.

    Returns tuple of (quality_label, color_hex).
    """
    score = validate_score(score)

    if score >= 0.8:
        return 'Excellent Match', MATCH_COLORS['excellent']
    elif score >= 0.6:
        return 'Good Match', MATCH_COLORS['good']
    elif score >= 0.4:
        return 'Fair Match', MATCH_COLORS['fair']
    else:
        return 'Possible Match', MATCH_COLORS['possible']


def load_associations_service() -> Optional[SponsorMatchService]:
    """Initialize and return the sponsor match service."""
    try:
        engine = get_engine()
        return SponsorMatchService(engine)
    except Exception as e:
        st.error(f"Database connection error: {e}")
        logger.error(f"Failed to initialize service: {e}")
        return None


def search_associations(service: SponsorMatchService, query: str) -> pd.DataFrame:
    """Search for associations using the service."""
    if not service:
        return pd.DataFrame()

    try:
        # Use the service search method
        results = service.search(query)

        # Filter to only associations
        if not results.empty:
            return results[results['type'] == 'association'].copy()
        return pd.DataFrame()

    except Exception as e:
        st.error(f"Search error: {e}")
        logger.error(f"Association search failed: {e}")
        return pd.DataFrame()


def render_search_results(sponsors: List[Dict], selected_idx: Optional[int] = None) -> Optional[int]:
    """
    Render sponsor search results with proper score formatting.

    This function creates the visual representation of search results,
    ensuring all scores are displayed correctly as percentages ‚â§ 100%.
    """
    if not sponsors:
        return None

    # Create results container
    st.subheader(f"Found {len(sponsors)} Potential Sponsors")

    # Add statistics
    scores = [validate_score(s['score']) for s in sponsors]
    avg_score = np.mean(scores)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Average Match", format_percentage(avg_score))
    with col2:
        st.metric("Best Match", format_percentage(max(scores)))
    with col3:
        excellent_count = sum(1 for s in scores if s >= 0.8)
        st.metric("Excellent Matches", excellent_count)

    st.divider()

    # Render each result
    clicked_idx = None

    for idx, sponsor in enumerate(sponsors):
        # Validate score
        score = validate_score(sponsor.get('score', 0), sponsor.get('name', 'Unknown'))
        quality_label, quality_color = get_match_quality(score)

        # Create result card
        is_selected = (selected_idx == idx)

        with st.container():
            col1, col2, col3 = st.columns([3, 1, 1])

            with col1:
                # Company name and info
                st.markdown(f"### {sponsor.get('name', 'Unknown Company')}")

                # Industry and size info
                industry = sponsor.get('industry', 'Unknown')
                size = sponsor.get('size_bucket', 'unknown').capitalize()
                st.caption(f"üìä {industry} | üìè {size} company")

            with col2:
                # Score display with color coding
                st.markdown(f"""
                <div style="text-align: center; padding: 10px;">
                    <div style="font-size: 24px; font-weight: bold; color: {quality_color};">
                        {format_percentage(score)}
                    </div>
                    <div style="font-size: 12px; color: {quality_color};">
                        {quality_label}
                    </div>
                </div>
                """, unsafe_allow_html=True)

            with col3:
                # Distance and action button
                distance = sponsor.get('distance', 0)
                st.metric("Distance", f"{distance:.1f} km")

                if st.button("View Details", key=f"view_{idx}"):
                    clicked_idx = idx

            # Score breakdown (expandable)
            with st.expander("Score Breakdown"):
                components = sponsor.get('components', {})

                # Create score breakdown chart
                if components:
                    breakdown_data = []
                    for component, value in components.items():
                        # Validate each component score
                        validated_value = validate_score(value, f"{sponsor['name']} - {component}")
                        breakdown_data.append({
                            'Component': component.replace('_', ' ').title(),
                            'Score': validated_value,
                            'Percentage': format_percentage(validated_value)
                        })

                    breakdown_df = pd.DataFrame(breakdown_data)

                    # Display as horizontal bar chart
                    st.bar_chart(breakdown_df.set_index('Component')['Score'])

                    # Show exact values
                    for row in breakdown_data:
                        st.caption(f"{row['Component']}: {row['Percentage']}")
                else:
                    st.info("Detailed score breakdown not available")

            st.divider()

    return clicked_idx


def render_map(
        selected_club: Optional[Dict],
        sponsors: List[Dict],
        selected_sponsor_idx: Optional[int] = None
) -> Dict:
    """
    Render interactive map with club and sponsor markers.

    This function creates a folium map showing the geographic distribution
    of the club and potential sponsors, with visual indicators of match quality.
    """
    # Default center on Gothenburg
    center_lat, center_lon = 57.7089, 11.9746
    zoom = 11

    # Center on selected club if available
    if selected_club and selected_club.get('lat') and selected_club.get('lon'):
        center_lat = float(selected_club['lat'])
        center_lon = float(selected_club['lon'])
        zoom = 12

    # Create map
    m = folium.Map(
        location=[center_lat, center_lon],
        zoom_start=zoom,
        tiles='OpenStreetMap'
    )

    # Add club marker
    if selected_club and selected_club.get('lat') and selected_club.get('lon'):
        club_popup = folium.Popup(
            f"""
            <div style='width: 200px'>
                <h4>{selected_club['name']}</h4>
                <p><b>Members:</b> {selected_club.get('member_count', 'N/A')}</p>
                <p><b>Size:</b> {selected_club.get('size_bucket', '').title()}</p>
                <p>{selected_club.get('address', '')}</p>
            </div>
            """,
            max_width=250
        )

        folium.Marker(
            location=[float(selected_club['lat']), float(selected_club['lon'])],
            popup=club_popup,
            icon=folium.Icon(color='purple', icon='star', prefix='fa'),
            tooltip=selected_club['name']
        ).add_to(m)

        # Add search radius circle
        if st.session_state.get('max_distance'):
            folium.Circle(
                location=[float(selected_club['lat']), float(selected_club['lon'])],
                radius=st.session_state.get('max_distance', DEFAULT_MAX_DISTANCE) * 1000,  # Convert km to m
                color='purple',
                fill=True,
                fillOpacity=0.1,
                tooltip=f"Search radius: {st.session_state.get('max_distance')} km"
            ).add_to(m)

    # Add sponsor markers
    if sponsors:
        # Create marker cluster for better performance with many markers
        marker_cluster = MarkerCluster().add_to(m)

        # Prepare heat map data
        heat_data = []

        for idx, sponsor in enumerate(sponsors):
            if sponsor.get('lat') and sponsor.get('lon'):
                # Validate score
                score = validate_score(sponsor.get('score', 0), sponsor['name'])
                quality_label, quality_color = get_match_quality(score)

                # Determine marker color based on score
                if score >= 0.8:
                    marker_color = 'darkgreen'
                elif score >= 0.6:
                    marker_color = 'green'
                elif score >= 0.4:
                    marker_color = 'orange'
                else:
                    marker_color = 'lightgray'

                # Create popup content
                popup_html = f"""
                <div style='width: 250px'>
                    <h4>{sponsor['name']}</h4>
                    <div style='background: {quality_color}; color: white; padding: 5px; margin: 5px 0; text-align: center; border-radius: 5px;'>
                        Match: {format_percentage(score)} - {quality_label}
                    </div>
                    <p><b>Distance:</b> {sponsor['distance']:.1f} km</p>
                    <p><b>Industry:</b> {sponsor.get('industry', 'N/A')}</p>
                    <p><b>Size:</b> {sponsor.get('size_bucket', '').title()}</p>
                </div>
                """

                # Special styling for selected sponsor
                if selected_sponsor_idx == idx:
                    icon = folium.Icon(color=marker_color, icon='building', prefix='fa', icon_color='yellow')
                else:
                    icon = folium.Icon(color=marker_color, icon='building', prefix='fa')

                # Add marker
                folium.Marker(
                    location=[float(sponsor['lat']), float(sponsor['lon'])],
                    popup=folium.Popup(popup_html, max_width=300),
                    icon=icon,
                    tooltip=f"{sponsor['name']} ({format_percentage(score)})"
                ).add_to(marker_cluster)

                # Add to heat map data (weight by score)
                heat_data.append([float(sponsor['lat']), float(sponsor['lon']), score])

        # Add heat map layer
        if heat_data:
            HeatMap(heat_data, radius=15, blur=10, max_zoom=13).add_to(m)

    # Display map
    map_data = st_folium(m, height=MAP_HEIGHT, width=None, key="search_map", returned_objects=["last_object_clicked"])

    return map_data


def render_sponsor_details(sponsor: Dict):
    """
    Render detailed sponsor information in a modal/expander.

    This function shows comprehensive information about a selected sponsor,
    including contact details and match analysis.
    """
    st.subheader(f"Sponsor Details: {sponsor['name']}")

    # Validate and display score prominently
    score = validate_score(sponsor.get('score', 0), sponsor['name'])
    quality_label, quality_color = get_match_quality(score)

    # Score display
    st.markdown(f"""
    <div style="background: {quality_color}; color: white; padding: 20px; border-radius: 10px; text-align: center; margin-bottom: 20px;">
        <h1 style="margin: 0; color: white;">{format_percentage(score)}</h1>
        <h3 style="margin: 0; color: white;">{quality_label}</h3>
    </div>
    """, unsafe_allow_html=True)

    # Company information
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### Company Information")
        st.write(f"**Industry:** {sponsor.get('industry', 'N/A')}")
        st.write(f"**Size:** {sponsor.get('size_bucket', 'unknown').capitalize()}")
        st.write(f"**Revenue:** {sponsor.get('revenue_ksek', 'N/A')} KSEK")
        st.write(f"**Employees:** {sponsor.get('employees', 'N/A')}")

    with col2:
        st.markdown("### Location")
        st.write(f"**Distance:** {sponsor.get('distance', 0):.1f} km")
        st.write(f"**Coordinates:** {sponsor.get('lat', 0):.4f}, {sponsor.get('lon', 0):.4f}")

    # Match analysis
    st.markdown("### Match Analysis")

    components = sponsor.get('components', {})
    if components:
        # Create detailed breakdown
        analysis_data = []

        for component, value in components.items():
            validated_value = validate_score(value, f"{sponsor['name']} - {component}")

            # Provide interpretation
            if component == 'distance_score':
                interpretation = "Closer sponsors score higher"
            elif component == 'size_score':
                interpretation = "Similar-sized organizations match better"
            elif component == 'cluster_score':
                interpretation = "Geographic clustering indicates market synergy"
            elif component == 'industry_score':
                interpretation = "Industry alignment with sports/community"
            else:
                interpretation = ""

            analysis_data.append({
                'Factor': component.replace('_', ' ').title(),
                'Score': format_percentage(validated_value),
                'Interpretation': interpretation
            })

        # Display as table
        analysis_df = pd.DataFrame(analysis_data)
        st.table(analysis_df)

    # Action buttons
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("üìß Contact Sponsor", key="contact_sponsor"):
            st.info("Contact feature coming soon!")

    with col2:
        if st.button("üìÑ Generate Proposal", key="generate_proposal"):
            st.info("Proposal generation feature coming soon!")

    with col3:
        if st.button("üìä View Similar Sponsors", key="similar_sponsors"):
            st.info("Similar sponsors feature coming soon!")


def render_search_page():
    """
    Main function to render the search page.

    This orchestrates the entire search experience, from club selection
    through sponsor discovery and detailed analysis.
    """
    st.title("üîç Find Sponsors for Your Club")

    # Initialize session state
    if 'selected_club' not in st.session_state:
        st.session_state.selected_club = None
    if 'sponsors' not in st.session_state:
        st.session_state.sponsors = []
    if 'selected_sponsor_idx' not in st.session_state:
        st.session_state.selected_sponsor_idx = None

    # Initialize service
    service = load_associations_service()

    # Create layout
    col1, col2 = st.columns([2, 3])

    with col1:
        st.markdown("### Search Your Club")

        # Search interface
        search_query = st.text_input(
            "üèÜ Enter club name...",
            placeholder="Type at least 2 characters",
            key="club_search"
        )

        # Search parameters
        with st.expander("Search Options", expanded=True):
            max_distance = st.slider(
                "Maximum distance (km)",
                min_value=5,
                max_value=100,
                value=DEFAULT_MAX_DISTANCE,
                key="max_distance"
            )

            top_n = st.slider(
                "Number of sponsors to find",
                min_value=5,
                max_value=50,
                value=DEFAULT_TOP_N,
                key="top_n"
            )

            min_score = st.slider(
                "Minimum match score",
                min_value=0.0,
                max_value=1.0,
                value=SCORE_THRESHOLD,
                step=0.1,
                format="%.1f",
                key="min_score"
            )

        # Search for clubs
        if search_query and len(search_query) >= 2 and service:
            associations_df = search_associations(service, search_query)

            if not associations_df.empty:
                st.markdown("### Select Your Club")

                # Display search results
                for _, assoc in associations_df.iterrows():
                    display_name = f"{assoc['name']}"
                    if pd.notna(assoc.get('address')):
                        display_name += f" - {assoc['address']}"

                    if st.button(display_name, key=f"club_{assoc['id']}", use_container_width=True):
                        # Get full association details
                        club_details = service.get_association_by_name(assoc['name'])
                        if club_details:
                            st.session_state.selected_club = club_details
                            st.rerun()
            else:
                st.info("No clubs found. Try different search terms.")

        # Show selected club
        if st.session_state.selected_club:
            st.success(f"‚úÖ Selected: **{st.session_state.selected_club['name']}**")

            # Club details
            with st.expander("Club Details", expanded=True):
                st.write(f"**Size:** {st.session_state.selected_club.get('size_bucket', 'unknown').capitalize()}")
                st.write(f"**Members:** {st.session_state.selected_club.get('member_count', 'N/A')}")
                st.write(f"**Address:** {st.session_state.selected_club.get('address', 'N/A')}")

            # Find sponsors button
            if st.button("üéØ Find Sponsors", type="primary", use_container_width=True):
                with st.spinner("Searching for matching sponsors..."):
                    try:
                        # Use ML pipeline for recommendations
                        sponsors = score_and_rank(
                            association_id=st.session_state.selected_club['id'],
                            bucket=st.session_state.selected_club.get('size_bucket', 'medium'),
                            max_distance=max_distance,
                            top_n=top_n
                        )

                        # Filter by minimum score
                        sponsors = [s for s in sponsors if s['score'] >= min_score]

                        st.session_state.sponsors = sponsors

                        if sponsors:
                            st.success(f"Found {len(sponsors)} potential sponsors!")
                        else:
                            st.warning("No sponsors found matching your criteria. Try adjusting the search parameters.")

                    except Exception as e:
                        st.error(f"Error finding sponsors: {e}")
                        logger.error(f"Sponsor search failed: {e}", exc_info=True)
                        st.session_state.sponsors = []

    with col2:
        # Map section
        st.markdown("### Sponsor Map")

        # Display map
        map_data = render_map(
            st.session_state.selected_club,
            st.session_state.sponsors,
            st.session_state.selected_sponsor_idx
        )

        # Handle map clicks
        if map_data.get('last_object_clicked'):
            # Process map click to select sponsor
            clicked_popup = map_data['last_object_clicked'].get('popup')
            if clicked_popup:
                # Extract sponsor from popup (simplified - in production use proper ID mapping)
                for idx, sponsor in enumerate(st.session_state.sponsors):
                    if sponsor['name'] in clicked_popup:
                        st.session_state.selected_sponsor_idx = idx
                        break

    # Results section (below the columns)
    if st.session_state.sponsors:
        st.divider()

        # Render search results
        clicked_idx = render_search_results(
            st.session_state.sponsors,
            st.session_state.selected_sponsor_idx
        )

        # Update selected sponsor if clicked
        if clicked_idx is not None:
            st.session_state.selected_sponsor_idx = clicked_idx
            st.rerun()

    # Sponsor details modal
    if (st.session_state.selected_sponsor_idx is not None and
            st.session_state.selected_sponsor_idx < len(st.session_state.sponsors)):
        with st.expander("Sponsor Details", expanded=True):
            selected_sponsor = st.session_state.sponsors[st.session_state.selected_sponsor_idx]
            render_sponsor_details(selected_sponsor)

    # Debug information (only in development)
    if st.checkbox("Show Debug Info", value=False):
        st.markdown("### Debug Information")

        if st.session_state.sponsors:
            # Check for any scores > 1.0
            invalid_scores = [s for s in st.session_state.sponsors if s['score'] > 1.0]

            if invalid_scores:
                st.error(f"‚ö†Ô∏è Found {len(invalid_scores)} sponsors with scores > 100%!")
                for s in invalid_scores:
                    st.write(f"- {s['name']}: {s['score'] * 100:.1f}%")
            else:
                st.success("‚úÖ All scores are valid (‚â§ 100%)")

        # Score validation results
        if service:
            with st.spinner("Running score validation..."):
                validation_stats = service.validate_all_scores()

                st.json(validation_stats)


# Entry point
if __name__ == "__main__":
    render_search_page()


================================================================================
FIL: sponsor_match/core/__init__.py
================================================================================



================================================================================
FIL: sponsor_match/core/config.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

# Fix 1: Update sponsor_match/core/config.py
# The password has special characters that need proper URL encoding

import os
from pathlib import Path
from urllib.parse import quote_plus

from dotenv import load_dotenv

load_dotenv()

# Base directories
BASE_DIR = Path(__file__).parent.parent.parent.resolve()
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"


# Database configuration - Fixed
def get_database_url():
    mysql_user = os.getenv("MYSQL_USER", "sponsor_user")
    mysql_password = os.getenv("MYSQL_PASSWORD", "Sports-2025?!")
    mysql_host = os.getenv("MYSQL_HOST", "localhost")
    mysql_port = os.getenv("MYSQL_PORT", "3306")
    mysql_db = os.getenv("MYSQL_DB", "sponsor_registry")

    # URL encode password to handle special characters
    encoded_password = quote_plus(mysql_password)

    return f"mysql+pymysql://{mysql_user}:{encoded_password}@{mysql_host}:{mysql_port}/{mysql_db}"


DATABASE_URL = get_database_url()

# App constants
APP_TITLE = os.getenv("APP_TITLE", "SponsorMatch AI")
LOGO_PATH = os.getenv("LOGO_PATH", str(BASE_DIR / "assets" / "logo.png"))
STREAMLIT_PAGE_ICON = "‚öΩ"

# Other settings
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
N_CLUSTERS = int(os.getenv("N_CLUSTERS", 5))
RANDOM_STATE = int(os.getenv("CLUSTER_RANDOM_STATE", 42))

================================================================================
FIL: sponsor_match/core/db.py
================================================================================

# This script has been annotated with comments in British English.
# Detailed comments explaining each section have been added as requested.

import logging

from dotenv import load_dotenv
from sqlalchemy import create_engine
from sqlalchemy.exc import SQLAlchemyError

load_dotenv()
_engine = None


def get_engine():
    global _engine
    if _engine is None:
        # Get URL from config
        from sponsor_match.core.config import DATABASE_URL

        if not DATABASE_URL:
            raise RuntimeError("DATABASE_URL not configured")

        try:
            _engine = create_engine(
                DATABASE_URL,
                pool_size=5,
                max_overflow=10,
                pool_recycle=3600,
                pool_pre_ping=True,  # Test connections before use
                echo=False,
            )
            logging.info("Database engine created successfully")
        except SQLAlchemyError as e:
            logging.error(f"Failed to create database engine: {e}")
            raise
    return _engine


